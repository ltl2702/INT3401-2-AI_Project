{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11182321,"sourceType":"datasetVersion","datasetId":6979951}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\nimport seaborn as sns\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import classification_report\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n# Cài đặt \n!pip install xgboost\n!pip install scikit-learn==1.2.2 imbalanced-learn==0.10.1\nimport warnings\nwarnings.simplefilter('ignore', FutureWarning)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-04T03:57:08.760032Z","iopub.execute_input":"2025-05-04T03:57:08.760388Z","iopub.status.idle":"2025-05-04T03:57:20.337019Z","shell.execute_reply.started":"2025-05-04T03:57:08.760364Z","shell.execute_reply":"2025-05-04T03:57:20.335717Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.0.3)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.26.4)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.15.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->xgboost) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->xgboost) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->xgboost) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->xgboost) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->xgboost) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->xgboost) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->xgboost) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->xgboost) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->xgboost) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->xgboost) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->xgboost) (2024.2.0)\nRequirement already satisfied: scikit-learn==1.2.2 in /usr/local/lib/python3.11/dist-packages (1.2.2)\nCollecting imbalanced-learn==0.10.1\n  Downloading imbalanced_learn-0.10.1-py3-none-any.whl.metadata (8.2 kB)\nRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (1.15.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (3.6.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn==1.2.2) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn==1.2.2) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn==1.2.2) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn==1.2.2) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn==1.2.2) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn==1.2.2) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn==1.2.2) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn==1.2.2) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17.3->scikit-learn==1.2.2) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17.3->scikit-learn==1.2.2) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17.3->scikit-learn==1.2.2) (2024.2.0)\nDownloading imbalanced_learn-0.10.1-py3-none-any.whl (226 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.0/226.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: imbalanced-learn\n  Attempting uninstall: imbalanced-learn\n    Found existing installation: imbalanced-learn 0.13.0\n    Uninstalling imbalanced-learn-0.13.0:\n      Successfully uninstalled imbalanced-learn-0.13.0\nSuccessfully installed imbalanced-learn-0.10.1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\n\ndf01 = pd.read_csv('/kaggle/input/clean-aws-month/final_data/filled_data_april.csv')\ndf02 = pd.read_csv('/kaggle/input/clean-aws-month/final_data/filled_data_october.csv')\n\n# Ghép 2 file lại với nhau\ndata_filled = pd.concat([df01, df02], ignore_index=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T03:57:20.339169Z","iopub.execute_input":"2025-05-04T03:57:20.339905Z","iopub.status.idle":"2025-05-04T03:57:30.175371Z","shell.execute_reply.started":"2025-05-04T03:57:20.339877Z","shell.execute_reply":"2025-05-04T03:57:30.174388Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# 1. Xử lý dữ liệu bị thiếu","metadata":{}},{"cell_type":"code","source":"# df_cleaned = data.copy()\n# df_cleaned = df_cleaned.drop(columns=['B04B', 'B05B', 'B06B', 'VSB', 'CIN'])\n\n# df_cleaned = df_cleaned[~((df_cleaned['AWS'] == -np.inf) | (df_cleaned['AWS'].isnull()))]\n# df_cleaned = df_cleaned[~((df_cleaned['SLHF'] == 9999) | (df_cleaned['SSHF'] == 9999))]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T03:57:30.176381Z","iopub.execute_input":"2025-05-04T03:57:30.176732Z","iopub.status.idle":"2025-05-04T03:57:30.181750Z","shell.execute_reply.started":"2025-05-04T03:57:30.176704Z","shell.execute_reply":"2025-05-04T03:57:30.180536Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# data_filled = df_cleaned.fillna(df_cleaned.median(numeric_only=True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T03:57:30.183810Z","iopub.execute_input":"2025-05-04T03:57:30.184171Z","iopub.status.idle":"2025-05-04T03:57:30.199055Z","shell.execute_reply.started":"2025-05-04T03:57:30.184143Z","shell.execute_reply":"2025-05-04T03:57:30.197990Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# 2. Chia train test","metadata":{}},{"cell_type":"code","source":"def split_data_by_multiple_ranges(df, train_ranges):\n    train_mask = False\n    for start, end in train_ranges:\n        train_mask |= (df['datetime'] >= start) & (df['datetime'] < end)\n    train_df = df[train_mask]\n    test_df = df[~train_mask]\n    return train_df, test_df\n\ndef convert_rain_label(df):\n    df['AWS'] = df['AWS'].apply(lambda x: 1 if x > 0 else 0)\n    return df\n\n# Gắn nhãn\ndf_all1 = convert_rain_label(data_filled)\n\n# Chuyển datetime nếu chưa\ndf_all1['datetime'] = pd.to_datetime(df_all1['datetime'])\n\n# Chọn các khoảng train: tháng 4/2019, 10/2019, 4/2020\ntrain_ranges = [\n    (\"2019-04-01\", \"2019-04-30\"),\n    (\"2019-10-01\", \"2019-10-31\"),\n    (\"2020-04-01\", \"2020-04-30\"),\n]\n\n# Tách train/test theo mốc trên\ntrain_df, test_df = split_data_by_multiple_ranges(df_all1, train_ranges)\n\n# Giữ lại chỉ test tháng 10/2020\ntest_df = test_df[\n    (test_df['datetime'] >= \"2020-10-01\") & (test_df['datetime'] <= \"2020-10-31\")\n]\n\n# Kết quả\nprint(f\"Train set: {train_df.shape}\")\nprint(f\"Test set (October 2020): {test_df.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T03:57:30.200131Z","iopub.execute_input":"2025-05-04T03:57:30.200472Z","iopub.status.idle":"2025-05-04T03:57:30.801487Z","shell.execute_reply.started":"2025-05-04T03:57:30.200439Z","shell.execute_reply":"2025-05-04T03:57:30.800430Z"}},"outputs":[{"name":"stdout","text":"Train set: (428242, 33)\nTest set (October 2020): (207094, 33)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"X_train = train_df.drop(columns=['AWS', 'datetime', 'row','col'])\ny_train = train_df['AWS']\n\nX_test = test_df.drop(columns=['AWS', 'datetime', 'row','col'])\ny_test = test_df['AWS']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T03:57:30.802714Z","iopub.execute_input":"2025-05-04T03:57:30.803044Z","iopub.status.idle":"2025-05-04T03:57:30.869556Z","shell.execute_reply.started":"2025-05-04T03:57:30.803018Z","shell.execute_reply":"2025-05-04T03:57:30.868650Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# 3. Chuẩn hóa","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = MinMaxScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\nX_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\nX_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T03:57:30.870534Z","iopub.execute_input":"2025-05-04T03:57:30.870844Z","iopub.status.idle":"2025-05-04T03:57:31.059943Z","shell.execute_reply.started":"2025-05-04T03:57:30.870815Z","shell.execute_reply":"2025-05-04T03:57:31.059170Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# 4. Chọn feature","metadata":{}},{"cell_type":"code","source":"top_features = ['B14B', 'I2B', 'TCLW', 'R500', 'R850', 'CAPE', 'U850', 'B10B', 'PEV', 'SLOR', 'R250', 'KX', 'V250', 'U250', 'TCWV']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T03:57:31.060835Z","iopub.execute_input":"2025-05-04T03:57:31.061060Z","iopub.status.idle":"2025-05-04T03:57:31.066162Z","shell.execute_reply.started":"2025-05-04T03:57:31.061038Z","shell.execute_reply":"2025-05-04T03:57:31.065324Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# X_train_selected = X_train_scaled[top_features]\n# X_test_selected = X_test_scaled[top_features]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T03:57:31.067263Z","iopub.execute_input":"2025-05-04T03:57:31.067500Z","iopub.status.idle":"2025-05-04T03:57:31.082747Z","shell.execute_reply.started":"2025-05-04T03:57:31.067481Z","shell.execute_reply":"2025-05-04T03:57:31.081855Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"#Performance evaluation\ndef print_scores(y_true, y_pred):\n  print(classification_report(y_true, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T03:57:31.085606Z","iopub.execute_input":"2025-05-04T03:57:31.085917Z","iopub.status.idle":"2025-05-04T03:57:31.101126Z","shell.execute_reply.started":"2025-05-04T03:57:31.085899Z","shell.execute_reply":"2025-05-04T03:57:31.100117Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"# 5. Thêm class weight","metadata":{}},{"cell_type":"code","source":"import xgboost as xgb\n\nmodel_xgb = xgb.XGBClassifier(random_state=42, n_estimators = 200)\nmodel_xgb.fit(X_train, y_train)\n\ny_pred = model_xgb.predict(X_test)\nprint_scores( y_test, y_pred)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T03:57:31.102173Z","iopub.execute_input":"2025-05-04T03:57:31.102543Z","iopub.status.idle":"2025-05-04T03:57:38.333075Z","shell.execute_reply.started":"2025-05-04T03:57:31.102514Z","shell.execute_reply":"2025-05-04T03:57:38.332076Z"}},"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.85      0.93      0.89    159566\n           1       0.66      0.47      0.55     47528\n\n    accuracy                           0.82    207094\n   macro avg       0.76      0.70      0.72    207094\nweighted avg       0.81      0.82      0.81    207094\n\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import xgboost as xgb\n\nmodel_xgb = xgb.XGBClassifier(random_state=42, n_estimators = 200)\nmodel_xgb.fit(X_train_scaled, y_train)\n\ny_pred = model_xgb.predict(X_test_scaled)\nprint_scores( y_test, y_pred)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T03:57:38.334204Z","iopub.execute_input":"2025-05-04T03:57:38.334513Z","iopub.status.idle":"2025-05-04T03:57:45.355052Z","shell.execute_reply.started":"2025-05-04T03:57:38.334482Z","shell.execute_reply":"2025-05-04T03:57:45.353929Z"}},"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.85      0.93      0.89    159566\n           1       0.66      0.47      0.55     47528\n\n    accuracy                           0.82    207094\n   macro avg       0.76      0.70      0.72    207094\nweighted avg       0.81      0.82      0.81    207094\n\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import xgboost as xgb\n\nmodel_xgb = xgb.XGBClassifier(random_state=42, n_estimators = 200, scale_pos_weight=11.32)\nmodel_xgb.fit(X_train_scaled, y_train)\n\ny_pred = model_xgb.predict(X_test_scaled)\nprint_scores( y_test, y_pred)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T03:57:45.356156Z","iopub.execute_input":"2025-05-04T03:57:45.356402Z","iopub.status.idle":"2025-05-04T03:57:54.025832Z","shell.execute_reply.started":"2025-05-04T03:57:45.356382Z","shell.execute_reply":"2025-05-04T03:57:54.024969Z"}},"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.90      0.77      0.83    159566\n           1       0.48      0.71      0.58     47528\n\n    accuracy                           0.76    207094\n   macro avg       0.69      0.74      0.70    207094\nweighted avg       0.80      0.76      0.77    207094\n\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import xgboost as xgb\n\nmodel_xgb = xgb.XGBClassifier(random_state=42, n_estimators = 200, scale_pos_weight=11.32)\nmodel_xgb.fit(X_train_scaled[top_features], y_train)\n\ny_pred = model_xgb.predict(X_test_scaled[top_features])\nprint_scores( y_test, y_pred)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T03:57:54.026725Z","iopub.execute_input":"2025-05-04T03:57:54.026971Z","iopub.status.idle":"2025-05-04T03:57:58.878297Z","shell.execute_reply.started":"2025-05-04T03:57:54.026951Z","shell.execute_reply":"2025-05-04T03:57:58.877367Z"}},"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.86      0.76      0.81    159566\n           1       0.43      0.60      0.50     47528\n\n    accuracy                           0.72    207094\n   macro avg       0.64      0.68      0.65    207094\nweighted avg       0.76      0.72      0.74    207094\n\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"=> Giải pháp:\n\n1. **Giữ mô hình đã tối ưu + threshold = 0.6** để triển khai hoặc đánh giá cuối cùng.\n2. Thử thêm:\n\n   * Tối ưu `max_depth`, `gamma`, `min_child_weight`, `subsample` bằng GridSearchCV hoặc Optuna.\n   * Dùng **cross-validation phân tầng (StratifiedKFold)** để đánh giá mô hình ổn định hơn.\n3. Nếu cần **giải thích mô hình**, có thể dùng SHAP để giải thích đóng góp các feature.","metadata":{}},{"cell_type":"markdown","source":"**Tuning XGBoost không chọn đặc trưng với optuna**","metadata":{}},{"cell_type":"code","source":"import xgboost as xgb\n\nmodel_xgb = xgb.XGBClassifier(\n    n_estimators=200,\n    max_depth=6,\n    learning_rate=0.1,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    scale_pos_weight=11.32,\n    random_state=42\n)\nmodel_xgb.fit(X_train_scaled, y_train)\n\n\ny_pred = model_xgb.predict(X_test_scaled)\nprint_scores( y_test, y_pred)\n\ny_probs = model_xgb.predict_proba(X_test_scaled)[:,1]\n\nbest_thresh = 0.0\nbest_f1 = 0.0\nfor t in np.arange(0.1, 0.9, 0.05):\n    y_pred = (y_probs >= t).astype(int)\n    f1 = f1_score(y_test, y_pred)\n    if f1 > best_f1:\n        best_f1 = f1\n        best_thresh = t\n\nprint(f\"Best threshold: {best_thresh}, F1: {best_f1}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T03:57:58.879319Z","iopub.execute_input":"2025-05-04T03:57:58.879641Z","iopub.status.idle":"2025-05-04T03:58:07.539032Z","shell.execute_reply.started":"2025-05-04T03:57:58.879620Z","shell.execute_reply":"2025-05-04T03:58:07.538011Z"}},"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.97      0.65      0.78    159566\n           1       0.44      0.93      0.60     47528\n\n    accuracy                           0.72    207094\n   macro avg       0.71      0.79      0.69    207094\nweighted avg       0.85      0.72      0.74    207094\n\nBest threshold: 0.7000000000000002, F1: 0.6357567891037204\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"import optuna\nimport numpy as np\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import train_test_split\nimport xgboost as xgb\n\n\nTHRESHOLD = best_thresh\nSCALE_POS_WEIGHT = 11.32 \n\ndef objective(trial):\n    # Thử các tham số\n    param = {\n        'n_estimators': 200,\n        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n        'max_depth': trial.suggest_int('max_depth', 3, 10),\n        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n        'gamma': trial.suggest_float('gamma', 0, 5),\n        'scale_pos_weight': SCALE_POS_WEIGHT,\n        'random_state': 42,\n        'verbosity': 0,\n        'n_jobs': -1,\n        'use_label_encoder': False,\n        'eval_metric': 'logloss'\n    }\n\n    model = xgb.XGBClassifier(**param)\n    model.fit(X_train_scaled, y_train)\n\n    # Dự đoán xác suất\n    y_probs = model.predict_proba(X_test_scaled)[:, 1]\n    y_pred = (y_probs >= THRESHOLD).astype(int)\n\n    # Trả về F1-score của lớp mưa (label=1)\n    return f1_score(y_test, y_pred, pos_label=1)\n\n# Tối ưu với Optuna\nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=50)  # Có thể tăng trials lên 100+\n\n# In kết quả tốt nhất\nprint(\"Best trial:\")\nprint(study.best_trial)\nprint(\"Best hyperparameters:\")\nfor key, value in study.best_trial.params.items():\n    print(f\"{key}: {value}\")\n\n# Huấn luyện lại với tham số tốt nhất\nbest_params = study.best_trial.params\nbest_params.update({\n    'n_estimators': 200,\n    'scale_pos_weight': SCALE_POS_WEIGHT,\n    'random_state': 42,\n    'use_label_encoder': False,\n    'eval_metric': 'logloss'\n})\n\nbest_model = xgb.XGBClassifier(**best_params)\nbest_model.fit(X_train_scaled, y_train)\n\n# Dự đoán với threshold\ny_probs = best_model.predict_proba(X_test_scaled)[:, 1]\ny_pred_thresh = (y_probs >= THRESHOLD).astype(int)\n\n# In kết quả\nfrom sklearn.metrics import classification_report\nprint(f\"\\nClassification report with threshold = {THRESHOLD}:\")\nprint(classification_report(y_test, y_pred_thresh))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T03:58:07.540207Z","iopub.execute_input":"2025-05-04T03:58:07.540550Z","iopub.status.idle":"2025-05-04T04:06:17.547971Z","shell.execute_reply.started":"2025-05-04T03:58:07.540521Z","shell.execute_reply":"2025-05-04T04:06:17.547170Z"}},"outputs":[{"name":"stderr","text":"[I 2025-05-04 03:58:07,842] A new study created in memory with name: no-name-e376fad6-f30c-48fd-873c-d9ad988f03d0\n[I 2025-05-04 03:58:18,522] Trial 0 finished with value: 0.5837567697551387 and parameters: {'learning_rate': 0.12917314409259603, 'max_depth': 9, 'min_child_weight': 10, 'subsample': 0.6877735807070782, 'colsample_bytree': 0.7806369223507554, 'gamma': 1.0603062289311964}. Best is trial 0 with value: 0.5837567697551387.\n[I 2025-05-04 03:58:31,434] Trial 1 finished with value: 0.5279821778167826 and parameters: {'learning_rate': 0.10441659759468691, 'max_depth': 9, 'min_child_weight': 2, 'subsample': 0.9124454375621692, 'colsample_bytree': 0.8395259105310269, 'gamma': 3.1208685454310485}. Best is trial 0 with value: 0.5837567697551387.\n[I 2025-05-04 03:58:38,027] Trial 2 finished with value: 0.6600131275560865 and parameters: {'learning_rate': 0.1660740667868559, 'max_depth': 6, 'min_child_weight': 8, 'subsample': 0.9554404477221969, 'colsample_bytree': 0.8510629944282961, 'gamma': 2.452086666878456}. Best is trial 2 with value: 0.6600131275560865.\n[I 2025-05-04 03:58:45,851] Trial 3 finished with value: 0.6681908582501827 and parameters: {'learning_rate': 0.14566812504662993, 'max_depth': 7, 'min_child_weight': 9, 'subsample': 0.6454889121369269, 'colsample_bytree': 0.7285396267841306, 'gamma': 3.917903582852751}. Best is trial 3 with value: 0.6681908582501827.\n[I 2025-05-04 03:59:00,344] Trial 4 finished with value: 0.6342943546341117 and parameters: {'learning_rate': 0.0699427643535552, 'max_depth': 10, 'min_child_weight': 3, 'subsample': 0.7244471445468974, 'colsample_bytree': 0.5230703919176534, 'gamma': 1.500615132459418}. Best is trial 3 with value: 0.6681908582501827.\n[I 2025-05-04 03:59:09,752] Trial 5 finished with value: 0.619475406199745 and parameters: {'learning_rate': 0.10756126641838769, 'max_depth': 8, 'min_child_weight': 7, 'subsample': 0.5179006982903058, 'colsample_bytree': 0.7876727980973287, 'gamma': 0.1578790977662281}. Best is trial 3 with value: 0.6681908582501827.\n[I 2025-05-04 03:59:16,058] Trial 6 finished with value: 0.6303837811517861 and parameters: {'learning_rate': 0.052929500776742584, 'max_depth': 5, 'min_child_weight': 4, 'subsample': 0.6895566026508194, 'colsample_bytree': 0.9840398460118581, 'gamma': 3.6128633913027426}. Best is trial 3 with value: 0.6681908582501827.\n[I 2025-05-04 03:59:21,932] Trial 7 finished with value: 0.6413295693475294 and parameters: {'learning_rate': 0.20423493967100734, 'max_depth': 5, 'min_child_weight': 9, 'subsample': 0.7949012872505238, 'colsample_bytree': 0.6719248910509933, 'gamma': 2.05206577047372}. Best is trial 3 with value: 0.6681908582501827.\n[I 2025-05-04 03:59:32,523] Trial 8 finished with value: 0.6241608156198903 and parameters: {'learning_rate': 0.15443627227318044, 'max_depth': 8, 'min_child_weight': 10, 'subsample': 0.6163020542575439, 'colsample_bytree': 0.7615259600410735, 'gamma': 1.1057201840389064}. Best is trial 3 with value: 0.6681908582501827.\n[I 2025-05-04 03:59:37,813] Trial 9 finished with value: 0.6304162631697745 and parameters: {'learning_rate': 0.06421248634844615, 'max_depth': 4, 'min_child_weight': 6, 'subsample': 0.8542601135681613, 'colsample_bytree': 0.8001487666990205, 'gamma': 4.521019869228423}. Best is trial 3 with value: 0.6681908582501827.\n[I 2025-05-04 03:59:42,662] Trial 10 finished with value: 0.6475972718010934 and parameters: {'learning_rate': 0.2855465692310302, 'max_depth': 3, 'min_child_weight': 5, 'subsample': 0.5020959529025876, 'colsample_bytree': 0.6507759324994769, 'gamma': 4.9519031475206186}. Best is trial 3 with value: 0.6681908582501827.\n[I 2025-05-04 03:59:49,450] Trial 11 finished with value: 0.5676447781904257 and parameters: {'learning_rate': 0.2353381374401532, 'max_depth': 6, 'min_child_weight': 8, 'subsample': 0.9893460665770181, 'colsample_bytree': 0.9235120276827207, 'gamma': 3.05173769811562}. Best is trial 3 with value: 0.6681908582501827.\n[I 2025-05-04 03:59:58,729] Trial 12 finished with value: 0.6057186210820806 and parameters: {'learning_rate': 0.19826305134781452, 'max_depth': 7, 'min_child_weight': 8, 'subsample': 0.6217514716128968, 'colsample_bytree': 0.6721843117735659, 'gamma': 3.926341627774643}. Best is trial 3 with value: 0.6681908582501827.\n[I 2025-05-04 04:00:05,376] Trial 13 finished with value: 0.6249394108037271 and parameters: {'learning_rate': 0.1808655265529849, 'max_depth': 6, 'min_child_weight': 7, 'subsample': 0.9959706503276399, 'colsample_bytree': 0.8728061878318116, 'gamma': 2.6213043482944505}. Best is trial 3 with value: 0.6681908582501827.\n[I 2025-05-04 04:00:13,102] Trial 14 finished with value: 0.5497711425760363 and parameters: {'learning_rate': 0.24165603835083335, 'max_depth': 7, 'min_child_weight': 9, 'subsample': 0.7934377100948612, 'colsample_bytree': 0.5924217686361328, 'gamma': 2.213099117950839}. Best is trial 3 with value: 0.6681908582501827.\n[I 2025-05-04 04:00:19,213] Trial 15 finished with value: 0.6495039013582506 and parameters: {'learning_rate': 0.1509560684855715, 'max_depth': 5, 'min_child_weight': 6, 'subsample': 0.5912941727768417, 'colsample_bytree': 0.7187725609104016, 'gamma': 4.058975615498165}. Best is trial 3 with value: 0.6681908582501827.\n[I 2025-05-04 04:00:28,711] Trial 16 finished with value: 0.6313396036891609 and parameters: {'learning_rate': 0.10622958928737034, 'max_depth': 8, 'min_child_weight': 8, 'subsample': 0.8749017158370612, 'colsample_bytree': 0.8921781725528632, 'gamma': 3.2711345106327485}. Best is trial 3 with value: 0.6681908582501827.\n[I 2025-05-04 04:00:36,739] Trial 17 finished with value: 0.6352859495830594 and parameters: {'learning_rate': 0.033062661008008365, 'max_depth': 6, 'min_child_weight': 9, 'subsample': 0.9203257115970216, 'colsample_bytree': 0.9715014066839667, 'gamma': 2.476912665863558}. Best is trial 3 with value: 0.6681908582501827.\n[I 2025-05-04 04:00:41,630] Trial 18 finished with value: 0.6415993907083016 and parameters: {'learning_rate': 0.16463835227891202, 'max_depth': 3, 'min_child_weight': 1, 'subsample': 0.5653818049286075, 'colsample_bytree': 0.7240329366987036, 'gamma': 1.7526635482382553}. Best is trial 3 with value: 0.6681908582501827.\n[I 2025-05-04 04:00:49,610] Trial 19 finished with value: 0.571616568838385 and parameters: {'learning_rate': 0.22836146877090258, 'max_depth': 7, 'min_child_weight': 7, 'subsample': 0.7872623317451203, 'colsample_bytree': 0.8403404316929645, 'gamma': 4.421684736494651}. Best is trial 3 with value: 0.6681908582501827.\n[I 2025-05-04 04:00:54,940] Trial 20 finished with value: 0.63650613885743 and parameters: {'learning_rate': 0.13071832011797913, 'max_depth': 4, 'min_child_weight': 5, 'subsample': 0.6531445994503997, 'colsample_bytree': 0.5901176362310366, 'gamma': 0.2009149710178848}. Best is trial 3 with value: 0.6681908582501827.\n[I 2025-05-04 04:01:01,865] Trial 21 finished with value: 0.6494887907740945 and parameters: {'learning_rate': 0.1437911000907466, 'max_depth': 5, 'min_child_weight': 6, 'subsample': 0.5669968230515532, 'colsample_bytree': 0.7208845115861645, 'gamma': 4.054778644584796}. Best is trial 3 with value: 0.6681908582501827.\n[I 2025-05-04 04:01:08,132] Trial 22 finished with value: 0.6485076506773064 and parameters: {'learning_rate': 0.17791568999483248, 'max_depth': 5, 'min_child_weight': 7, 'subsample': 0.5838210907143312, 'colsample_bytree': 0.7134569655689795, 'gamma': 3.6172302446685705}. Best is trial 3 with value: 0.6681908582501827.\n[I 2025-05-04 04:01:13,484] Trial 23 finished with value: 0.6577576076826452 and parameters: {'learning_rate': 0.20412844250185552, 'max_depth': 4, 'min_child_weight': 10, 'subsample': 0.7344406835596873, 'colsample_bytree': 0.8370479342415343, 'gamma': 4.966976776166745}. Best is trial 3 with value: 0.6681908582501827.\n[I 2025-05-04 04:01:18,804] Trial 24 finished with value: 0.6467892458599738 and parameters: {'learning_rate': 0.2720245636143768, 'max_depth': 4, 'min_child_weight': 10, 'subsample': 0.7420795194844543, 'colsample_bytree': 0.8279945535943986, 'gamma': 4.486587498257462}. Best is trial 3 with value: 0.6681908582501827.\n[I 2025-05-04 04:01:25,717] Trial 25 finished with value: 0.6537307461492299 and parameters: {'learning_rate': 0.1968123896791968, 'max_depth': 6, 'min_child_weight': 9, 'subsample': 0.6877521831412456, 'colsample_bytree': 0.9182224198936704, 'gamma': 2.7485150391936974}. Best is trial 3 with value: 0.6681908582501827.\n[I 2025-05-04 04:01:35,182] Trial 26 finished with value: 0.5707930568547969 and parameters: {'learning_rate': 0.2575406338291247, 'max_depth': 7, 'min_child_weight': 10, 'subsample': 0.7667391460333105, 'colsample_bytree': 0.9380621707148492, 'gamma': 4.913066595262053}. Best is trial 3 with value: 0.6681908582501827.\n[I 2025-05-04 04:01:40,485] Trial 27 finished with value: 0.6495590446100539 and parameters: {'learning_rate': 0.21113278263215282, 'max_depth': 4, 'min_child_weight': 8, 'subsample': 0.8288039545716113, 'colsample_bytree': 0.858785542856991, 'gamma': 3.5600570498268893}. Best is trial 3 with value: 0.6681908582501827.\n[I 2025-05-04 04:01:45,174] Trial 28 finished with value: 0.641137889914015 and parameters: {'learning_rate': 0.1781491397642266, 'max_depth': 3, 'min_child_weight': 9, 'subsample': 0.7173376049803775, 'colsample_bytree': 0.8135725201838993, 'gamma': 4.695584455924058}. Best is trial 3 with value: 0.6681908582501827.\n[I 2025-05-04 04:01:55,548] Trial 29 finished with value: 0.5979446479446479 and parameters: {'learning_rate': 0.12940480255756384, 'max_depth': 9, 'min_child_weight': 10, 'subsample': 0.6562454944944673, 'colsample_bytree': 0.7475005551651759, 'gamma': 4.235013190668557}. Best is trial 3 with value: 0.6681908582501827.\n[I 2025-05-04 04:02:04,658] Trial 30 finished with value: 0.6358793437996119 and parameters: {'learning_rate': 0.09259930972828878, 'max_depth': 8, 'min_child_weight': 10, 'subsample': 0.9471262963899181, 'colsample_bytree': 0.7756627612906637, 'gamma': 2.952741290358654}. Best is trial 3 with value: 0.6681908582501827.\n[I 2025-05-04 04:02:12,732] Trial 31 finished with value: 0.6404328921342244 and parameters: {'learning_rate': 0.21886436247547103, 'max_depth': 6, 'min_child_weight': 9, 'subsample': 0.6877886320343005, 'colsample_bytree': 0.9079320826054708, 'gamma': 2.6667468258194162}. Best is trial 3 with value: 0.6681908582501827.\n[I 2025-05-04 04:02:19,729] Trial 32 finished with value: 0.6433725788074439 and parameters: {'learning_rate': 0.19202213864984735, 'max_depth': 6, 'min_child_weight': 9, 'subsample': 0.6592564811330386, 'colsample_bytree': 0.9460971091306344, 'gamma': 3.3640468971447053}. Best is trial 3 with value: 0.6681908582501827.\n[I 2025-05-04 04:02:27,622] Trial 33 finished with value: 0.6491436684710268 and parameters: {'learning_rate': 0.16989455126095024, 'max_depth': 7, 'min_child_weight': 8, 'subsample': 0.7484444893420816, 'colsample_bytree': 0.8937040680074818, 'gamma': 1.5359341913800122}. Best is trial 3 with value: 0.6681908582501827.\n[I 2025-05-04 04:02:41,530] Trial 34 finished with value: 0.6136729985144916 and parameters: {'learning_rate': 0.1410309390861373, 'max_depth': 10, 'min_child_weight': 10, 'subsample': 0.721286971704819, 'colsample_bytree': 0.8701313073453238, 'gamma': 2.1617321483148224}. Best is trial 3 with value: 0.6681908582501827.\n[I 2025-05-04 04:02:52,388] Trial 35 finished with value: 0.6351820347056821 and parameters: {'learning_rate': 0.11435833382696463, 'max_depth': 9, 'min_child_weight': 9, 'subsample': 0.7021813890545645, 'colsample_bytree': 0.8499627663733509, 'gamma': 2.936876496962024}. Best is trial 3 with value: 0.6681908582501827.\n[I 2025-05-04 04:03:02,157] Trial 36 finished with value: 0.6630216178096624 and parameters: {'learning_rate': 0.08309864021436111, 'max_depth': 8, 'min_child_weight': 8, 'subsample': 0.6265791951822908, 'colsample_bytree': 0.9643384833091952, 'gamma': 3.8376212898351785}. Best is trial 3 with value: 0.6681908582501827.\n[I 2025-05-04 04:03:13,691] Trial 37 finished with value: 0.6456339658821614 and parameters: {'learning_rate': 0.08749961956173503, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.5351420524612934, 'colsample_bytree': 0.9641311888984295, 'gamma': 3.709758946201338}. Best is trial 3 with value: 0.6681908582501827.\n[I 2025-05-04 04:03:27,772] Trial 38 finished with value: 0.6608438001123331 and parameters: {'learning_rate': 0.017076279913981418, 'max_depth': 9, 'min_child_weight': 8, 'subsample': 0.6342434704117215, 'colsample_bytree': 0.7976434737235596, 'gamma': 4.7266510119696195}. Best is trial 3 with value: 0.6681908582501827.\n[I 2025-05-04 04:03:41,539] Trial 39 finished with value: 0.6632739748407123 and parameters: {'learning_rate': 0.027211156308132048, 'max_depth': 9, 'min_child_weight': 7, 'subsample': 0.6065073296837178, 'colsample_bytree': 0.9935722594919991, 'gamma': 3.8006427722132052}. Best is trial 3 with value: 0.6681908582501827.\n[I 2025-05-04 04:03:56,982] Trial 40 finished with value: 0.6615833218904226 and parameters: {'learning_rate': 0.015056293221866607, 'max_depth': 9, 'min_child_weight': 7, 'subsample': 0.6253356408906208, 'colsample_bytree': 0.9919780943867285, 'gamma': 4.251169326203477}. Best is trial 3 with value: 0.6681908582501827.\n[I 2025-05-04 04:04:11,733] Trial 41 finished with value: 0.6628555719067872 and parameters: {'learning_rate': 0.01673203371689398, 'max_depth': 9, 'min_child_weight': 7, 'subsample': 0.6215644555912712, 'colsample_bytree': 0.9879957766472869, 'gamma': 4.262650436320314}. Best is trial 3 with value: 0.6681908582501827.\n[I 2025-05-04 04:04:31,381] Trial 42 finished with value: 0.6680802506982765 and parameters: {'learning_rate': 0.014488985388700094, 'max_depth': 10, 'min_child_weight': 7, 'subsample': 0.5974000489667395, 'colsample_bytree': 0.9813004647942551, 'gamma': 4.275487884886396}. Best is trial 3 with value: 0.6681908582501827.\n[I 2025-05-04 04:04:46,948] Trial 43 finished with value: 0.6631251177774389 and parameters: {'learning_rate': 0.04216650985297911, 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.5991987479019069, 'colsample_bytree': 0.9998656230320256, 'gamma': 3.94404279945472}. Best is trial 3 with value: 0.6681908582501827.\n[I 2025-05-04 04:05:02,072] Trial 44 finished with value: 0.652638923315615 and parameters: {'learning_rate': 0.046287369113781715, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.5441797482725913, 'colsample_bytree': 0.9508464986074615, 'gamma': 3.845879534793567}. Best is trial 3 with value: 0.6681908582501827.\n[I 2025-05-04 04:05:16,286] Trial 45 finished with value: 0.6473180132283586 and parameters: {'learning_rate': 0.06798123184030044, 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.5960664566257485, 'colsample_bytree': 0.9985502093059131, 'gamma': 3.4562443084732304}. Best is trial 3 with value: 0.6681908582501827.\n[I 2025-05-04 04:05:33,726] Trial 46 finished with value: 0.6581797858467215 and parameters: {'learning_rate': 0.0335602516425821, 'max_depth': 10, 'min_child_weight': 4, 'subsample': 0.5488028060295949, 'colsample_bytree': 0.965653441318335, 'gamma': 3.8485627275619914}. Best is trial 3 with value: 0.6681908582501827.\n[I 2025-05-04 04:05:44,090] Trial 47 finished with value: 0.6610172316101723 and parameters: {'learning_rate': 0.05265220105203774, 'max_depth': 8, 'min_child_weight': 6, 'subsample': 0.5989151472634929, 'colsample_bytree': 0.9353465083347747, 'gamma': 4.051865908336166}. Best is trial 3 with value: 0.6681908582501827.\n[I 2025-05-04 04:05:59,097] Trial 48 finished with value: 0.6414814090975717 and parameters: {'learning_rate': 0.0795418008656614, 'max_depth': 10, 'min_child_weight': 7, 'subsample': 0.5103759963834189, 'colsample_bytree': 0.9744706278872556, 'gamma': 3.200799789110433}. Best is trial 3 with value: 0.6681908582501827.\n[I 2025-05-04 04:06:09,474] Trial 49 finished with value: 0.6590892833014077 and parameters: {'learning_rate': 0.03247985875017445, 'max_depth': 8, 'min_child_weight': 5, 'subsample': 0.6420259999436873, 'colsample_bytree': 0.6717403843648926, 'gamma': 4.675706756188392}. Best is trial 3 with value: 0.6681908582501827.\n","output_type":"stream"},{"name":"stdout","text":"Best trial:\nFrozenTrial(number=3, state=1, values=[0.6681908582501827], datetime_start=datetime.datetime(2025, 5, 4, 3, 58, 38, 28118), datetime_complete=datetime.datetime(2025, 5, 4, 3, 58, 45, 851666), params={'learning_rate': 0.14566812504662993, 'max_depth': 7, 'min_child_weight': 9, 'subsample': 0.6454889121369269, 'colsample_bytree': 0.7285396267841306, 'gamma': 3.917903582852751}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'learning_rate': FloatDistribution(high=0.3, log=False, low=0.01, step=None), 'max_depth': IntDistribution(high=10, log=False, low=3, step=1), 'min_child_weight': IntDistribution(high=10, log=False, low=1, step=1), 'subsample': FloatDistribution(high=1.0, log=False, low=0.5, step=None), 'colsample_bytree': FloatDistribution(high=1.0, log=False, low=0.5, step=None), 'gamma': FloatDistribution(high=5.0, log=False, low=0.0, step=None)}, trial_id=3, value=None)\nBest hyperparameters:\nlearning_rate: 0.14566812504662993\nmax_depth: 7\nmin_child_weight: 9\nsubsample: 0.6454889121369269\ncolsample_bytree: 0.7285396267841306\ngamma: 3.917903582852751\n\nClassification report with threshold = 0.7000000000000002:\n              precision    recall  f1-score   support\n\n           0       0.94      0.81      0.87    159566\n           1       0.56      0.83      0.67     47528\n\n    accuracy                           0.81    207094\n   macro avg       0.75      0.82      0.77    207094\nweighted avg       0.85      0.81      0.82    207094\n\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"**Tuning XGBoost có chọn đặc trưng với optuna**","metadata":{}},{"cell_type":"code","source":"import xgboost as xgb\n\nmodel_xgb = xgb.XGBClassifier(\n    n_estimators=200,\n    max_depth=6,\n    learning_rate=0.1,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    scale_pos_weight=11.32,\n    random_state=42\n)\nmodel_xgb.fit(X_train_scaled[top_features], y_train)\n\n\ny_pred = model_xgb.predict(X_test_scaled[top_features])\nprint_scores( y_test, y_pred)\n\ny_probs = model_xgb.predict_proba(X_test_scaled[top_features])[:,1]\n\nbest_thresh = 0.0\nbest_f1 = 0.0\nfor t in np.arange(0.1, 0.9, 0.05):\n    y_pred = (y_probs >= t).astype(int)\n    f1 = f1_score(y_test, y_pred)\n    if f1 > best_f1:\n        best_f1 = f1\n        best_thresh = t\n\nprint(f\"Best threshold: {best_thresh}, F1: {best_f1}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T04:06:17.548874Z","iopub.execute_input":"2025-05-04T04:06:17.549162Z","iopub.status.idle":"2025-05-04T04:06:24.411111Z","shell.execute_reply.started":"2025-05-04T04:06:17.549141Z","shell.execute_reply":"2025-05-04T04:06:24.410296Z"}},"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.97      0.62      0.75    159566\n           1       0.42      0.93      0.58     47528\n\n    accuracy                           0.69    207094\n   macro avg       0.69      0.78      0.67    207094\nweighted avg       0.84      0.69      0.71    207094\n\nBest threshold: 0.7500000000000002, F1: 0.6257327664585624\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"import optuna\nimport numpy as np\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import train_test_split\nimport xgboost as xgb\n\n\nTHRESHOLD = best_thresh\nSCALE_POS_WEIGHT = 11.32 \n\ndef objective(trial):\n    # Thử các tham số\n    param = {\n        'n_estimators': 200,\n        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n        'max_depth': trial.suggest_int('max_depth', 3, 10),\n        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n        'gamma': trial.suggest_float('gamma', 0, 5),\n        'scale_pos_weight': SCALE_POS_WEIGHT,\n        'random_state': 42,\n        'verbosity': 0,\n        'n_jobs': -1,\n        'use_label_encoder': False,\n        'eval_metric': 'logloss'\n    }\n\n    model = xgb.XGBClassifier(**param)\n    model.fit(X_train_scaled[top_features], y_train)\n\n    # Dự đoán xác suất\n    y_probs = model.predict_proba(X_test_scaled[top_features])[:, 1]\n    y_pred = (y_probs >= THRESHOLD).astype(int)\n\n    # Trả về F1-score của lớp mưa (label=1)\n    return f1_score(y_test, y_pred, pos_label=1)\n\n# Tối ưu với Optuna\nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=50)  # Có thể tăng trials lên 100+\n\n# In kết quả tốt nhất\nprint(\"Best trial:\")\nprint(study.best_trial)\nprint(\"Best hyperparameters:\")\nfor key, value in study.best_trial.params.items():\n    print(f\"{key}: {value}\")\n\n# Huấn luyện lại với tham số tốt nhất\nbest_params = study.best_trial.params\nbest_params.update({\n    'n_estimators': 200,\n    'scale_pos_weight': SCALE_POS_WEIGHT,\n    'random_state': 42,\n    'use_label_encoder': False,\n    'eval_metric': 'logloss'\n})\n\nbest_model = xgb.XGBClassifier(**best_params)\nbest_model.fit(X_train_scaled, y_train)\n\n# Dự đoán với threshold\ny_probs = best_model.predict_proba(X_test_scaled)[:, 1]\ny_pred_thresh = (y_probs >= THRESHOLD).astype(int)\n\n# In kết quả\nfrom sklearn.metrics import classification_report\n# print(\"\\nClassification report with threshold = 0.75:\")\nprint(f\"\\nClassification report with threshold = {THRESHOLD}:\")\nprint(classification_report(y_test, y_pred_thresh))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T04:06:24.412019Z","iopub.execute_input":"2025-05-04T04:06:24.412396Z","iopub.status.idle":"2025-05-04T04:11:41.631237Z","shell.execute_reply.started":"2025-05-04T04:06:24.412363Z","shell.execute_reply":"2025-05-04T04:11:41.630163Z"}},"outputs":[{"name":"stderr","text":"[I 2025-05-04 04:06:24,421] A new study created in memory with name: no-name-3e475a75-5c6e-4fde-8879-ed3490bc9bd9\n[I 2025-05-04 04:06:30,979] Trial 0 finished with value: 0.6517376512639421 and parameters: {'learning_rate': 0.05501805548093067, 'max_depth': 8, 'min_child_weight': 5, 'subsample': 0.9281113947048185, 'colsample_bytree': 0.6904772711215474, 'gamma': 3.8101173736328446}. Best is trial 0 with value: 0.6517376512639421.\n[I 2025-05-04 04:06:36,376] Trial 1 finished with value: 0.6447731529258877 and parameters: {'learning_rate': 0.021532949352925854, 'max_depth': 6, 'min_child_weight': 6, 'subsample': 0.7739285737167391, 'colsample_bytree': 0.8454808722709726, 'gamma': 4.790983412951543}. Best is trial 0 with value: 0.6517376512639421.\n[I 2025-05-04 04:06:40,151] Trial 2 finished with value: 0.6381947240842946 and parameters: {'learning_rate': 0.16072264453401341, 'max_depth': 4, 'min_child_weight': 5, 'subsample': 0.7267155543365673, 'colsample_bytree': 0.6392656494318474, 'gamma': 0.17625219903153577}. Best is trial 0 with value: 0.6517376512639421.\n[I 2025-05-04 04:06:44,762] Trial 3 finished with value: 0.6271444485703676 and parameters: {'learning_rate': 0.151401588333798, 'max_depth': 6, 'min_child_weight': 5, 'subsample': 0.9199805580133309, 'colsample_bytree': 0.6368148741043463, 'gamma': 1.0188861466659134}. Best is trial 0 with value: 0.6517376512639421.\n[I 2025-05-04 04:06:51,678] Trial 4 finished with value: 0.553940829450243 and parameters: {'learning_rate': 0.1444605046118346, 'max_depth': 9, 'min_child_weight': 4, 'subsample': 0.8518358520875124, 'colsample_bytree': 0.5696736683460222, 'gamma': 2.2220274281362413}. Best is trial 0 with value: 0.6517376512639421.\n[I 2025-05-04 04:06:57,014] Trial 5 finished with value: 0.631368722749032 and parameters: {'learning_rate': 0.10042592317234351, 'max_depth': 4, 'min_child_weight': 3, 'subsample': 0.616439876516887, 'colsample_bytree': 0.9100622814378112, 'gamma': 4.723252246041289}. Best is trial 0 with value: 0.6517376512639421.\n[I 2025-05-04 04:07:00,234] Trial 6 finished with value: 0.6102203714679373 and parameters: {'learning_rate': 0.21913665657007753, 'max_depth': 3, 'min_child_weight': 4, 'subsample': 0.9854725442297452, 'colsample_bytree': 0.7487151032869989, 'gamma': 0.477692094404899}. Best is trial 0 with value: 0.6517376512639421.\n[I 2025-05-04 04:07:04,973] Trial 7 finished with value: 0.6563207850329579 and parameters: {'learning_rate': 0.0733466913335298, 'max_depth': 6, 'min_child_weight': 7, 'subsample': 0.9486630446848907, 'colsample_bytree': 0.512640641423911, 'gamma': 2.3339037713409616}. Best is trial 7 with value: 0.6563207850329579.\n[I 2025-05-04 04:07:08,237] Trial 8 finished with value: 0.6281978313850823 and parameters: {'learning_rate': 0.134125401611014, 'max_depth': 3, 'min_child_weight': 10, 'subsample': 0.8090405004873429, 'colsample_bytree': 0.6229285824032968, 'gamma': 4.4061810760255815}. Best is trial 7 with value: 0.6563207850329579.\n[I 2025-05-04 04:07:11,863] Trial 9 finished with value: 0.6559736822330023 and parameters: {'learning_rate': 0.015459975668466828, 'max_depth': 3, 'min_child_weight': 9, 'subsample': 0.8627143065557811, 'colsample_bytree': 0.5755996781775421, 'gamma': 4.793016880335443}. Best is trial 7 with value: 0.6563207850329579.\n[I 2025-05-04 04:07:20,214] Trial 10 finished with value: 0.40835071937572814 and parameters: {'learning_rate': 0.28600661319963266, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.5297488685590768, 'colsample_bytree': 0.5118639526309618, 'gamma': 2.6462284426883658}. Best is trial 7 with value: 0.6563207850329579.\n[I 2025-05-04 04:07:26,603] Trial 11 finished with value: 0.67387786389575 and parameters: {'learning_rate': 0.01137936963554434, 'max_depth': 7, 'min_child_weight': 9, 'subsample': 0.9938895389829856, 'colsample_bytree': 0.5090965733503486, 'gamma': 2.9622584955748374}. Best is trial 11 with value: 0.67387786389575.\n[I 2025-05-04 04:07:32,686] Trial 12 finished with value: 0.6557180052072902 and parameters: {'learning_rate': 0.07211028317782421, 'max_depth': 7, 'min_child_weight': 8, 'subsample': 0.9920216237088059, 'colsample_bytree': 0.5084746113902125, 'gamma': 2.7483785881208975}. Best is trial 11 with value: 0.67387786389575.\n[I 2025-05-04 04:07:38,255] Trial 13 finished with value: 0.6518892692167093 and parameters: {'learning_rate': 0.06994555183713791, 'max_depth': 7, 'min_child_weight': 7, 'subsample': 0.6914338013264142, 'colsample_bytree': 0.7744074243050592, 'gamma': 1.7526906036310952}. Best is trial 11 with value: 0.67387786389575.\n[I 2025-05-04 04:07:43,093] Trial 14 finished with value: 0.6455780592657303 and parameters: {'learning_rate': 0.01814467139252985, 'max_depth': 5, 'min_child_weight': 8, 'subsample': 0.9157423326430514, 'colsample_bytree': 0.9954067420450405, 'gamma': 3.584941263755913}. Best is trial 11 with value: 0.67387786389575.\n[I 2025-05-04 04:07:49,015] Trial 15 finished with value: 0.6397532164066757 and parameters: {'learning_rate': 0.09783102720143932, 'max_depth': 8, 'min_child_weight': 10, 'subsample': 0.9931853671725585, 'colsample_bytree': 0.5019244749199477, 'gamma': 3.3091825491896967}. Best is trial 11 with value: 0.67387786389575.\n[I 2025-05-04 04:07:53,296] Trial 16 finished with value: 0.6386572143452878 and parameters: {'learning_rate': 0.04990569312080699, 'max_depth': 5, 'min_child_weight': 7, 'subsample': 0.8617098160108487, 'colsample_bytree': 0.5815441640228984, 'gamma': 1.6392792338898696}. Best is trial 11 with value: 0.67387786389575.\n[I 2025-05-04 04:08:00,828] Trial 17 finished with value: 0.5554351751534851 and parameters: {'learning_rate': 0.18623601674736795, 'max_depth': 8, 'min_child_weight': 8, 'subsample': 0.9309503913234886, 'colsample_bytree': 0.7182515375244107, 'gamma': 3.117217599954214}. Best is trial 11 with value: 0.67387786389575.\n[I 2025-05-04 04:08:05,674] Trial 18 finished with value: 0.650212034476887 and parameters: {'learning_rate': 0.09891006070920705, 'max_depth': 6, 'min_child_weight': 9, 'subsample': 0.6679409062907625, 'colsample_bytree': 0.8187266281454584, 'gamma': 1.9492830659443803}. Best is trial 11 with value: 0.67387786389575.\n[I 2025-05-04 04:08:10,223] Trial 19 finished with value: 0.6433912195416984 and parameters: {'learning_rate': 0.03894728870097272, 'max_depth': 5, 'min_child_weight': 7, 'subsample': 0.8090464997811444, 'colsample_bytree': 0.553773905026612, 'gamma': 1.003829636005228}. Best is trial 11 with value: 0.67387786389575.\n[I 2025-05-04 04:08:15,651] Trial 20 finished with value: 0.6135931253159321 and parameters: {'learning_rate': 0.2234673215399146, 'max_depth': 7, 'min_child_weight': 9, 'subsample': 0.5462024591128118, 'colsample_bytree': 0.6840762057546844, 'gamma': 1.3333210428391347}. Best is trial 11 with value: 0.67387786389575.\n[I 2025-05-04 04:08:19,901] Trial 21 finished with value: 0.666602825827682 and parameters: {'learning_rate': 0.01070605638511252, 'max_depth': 4, 'min_child_weight': 9, 'subsample': 0.8716431822969101, 'colsample_bytree': 0.5615758531962894, 'gamma': 4.018933139155678}. Best is trial 11 with value: 0.67387786389575.\n[I 2025-05-04 04:08:24,045] Trial 22 finished with value: 0.666973672777826 and parameters: {'learning_rate': 0.010873594089453067, 'max_depth': 4, 'min_child_weight': 10, 'subsample': 0.9474159151947162, 'colsample_bytree': 0.5466187138282804, 'gamma': 4.132837707031086}. Best is trial 11 with value: 0.67387786389575.\n[I 2025-05-04 04:08:28,252] Trial 23 finished with value: 0.6686119362442278 and parameters: {'learning_rate': 0.010261940151123264, 'max_depth': 4, 'min_child_weight': 10, 'subsample': 0.8752703630360709, 'colsample_bytree': 0.6068360314651393, 'gamma': 3.9765573047853575}. Best is trial 11 with value: 0.67387786389575.\n[I 2025-05-04 04:08:33,729] Trial 24 finished with value: 0.635147414066944 and parameters: {'learning_rate': 0.03710053228478367, 'max_depth': 4, 'min_child_weight': 10, 'subsample': 0.9535053741009415, 'colsample_bytree': 0.6103908115266993, 'gamma': 4.321468585929257}. Best is trial 11 with value: 0.67387786389575.\n[I 2025-05-04 04:08:38,097] Trial 25 finished with value: 0.6391151722030513 and parameters: {'learning_rate': 0.04133002510087401, 'max_depth': 5, 'min_child_weight': 10, 'subsample': 0.8847182996186687, 'colsample_bytree': 0.5464415406052644, 'gamma': 3.102364272922461}. Best is trial 11 with value: 0.67387786389575.\n[I 2025-05-04 04:08:45,207] Trial 26 finished with value: 0.6052060516529978 and parameters: {'learning_rate': 0.11617696386075695, 'max_depth': 9, 'min_child_weight': 10, 'subsample': 0.8153370599888407, 'colsample_bytree': 0.6705189567282608, 'gamma': 4.14295479860918}. Best is trial 11 with value: 0.67387786389575.\n[I 2025-05-04 04:08:48,998] Trial 27 finished with value: 0.6312364265469136 and parameters: {'learning_rate': 0.056386628290841005, 'max_depth': 4, 'min_child_weight': 9, 'subsample': 0.9619971406956199, 'colsample_bytree': 0.5955426816259347, 'gamma': 3.601948481444245}. Best is trial 11 with value: 0.67387786389575.\n[I 2025-05-04 04:08:53,184] Trial 28 finished with value: 0.6364669062246436 and parameters: {'learning_rate': 0.07984159051853827, 'max_depth': 5, 'min_child_weight': 8, 'subsample': 0.8983771941441705, 'colsample_bytree': 0.5360719889175637, 'gamma': 2.8401461438868068}. Best is trial 11 with value: 0.67387786389575.\n[I 2025-05-04 04:08:56,707] Trial 29 finished with value: 0.6345725923899784 and parameters: {'learning_rate': 0.03101935118311429, 'max_depth': 3, 'min_child_weight': 6, 'subsample': 0.956306545563017, 'colsample_bytree': 0.6518945081860714, 'gamma': 3.7487589405008452}. Best is trial 11 with value: 0.67387786389575.\n[I 2025-05-04 04:09:02,339] Trial 30 finished with value: 0.5445241822785875 and parameters: {'learning_rate': 0.2805021645019115, 'max_depth': 7, 'min_child_weight': 10, 'subsample': 0.7666810934074739, 'colsample_bytree': 0.7239589116365914, 'gamma': 3.3269507528073357}. Best is trial 11 with value: 0.67387786389575.\n[I 2025-05-04 04:09:07,572] Trial 31 finished with value: 0.6665098408217675 and parameters: {'learning_rate': 0.010776186974018621, 'max_depth': 4, 'min_child_weight': 9, 'subsample': 0.8870786055234595, 'colsample_bytree': 0.5398611994423572, 'gamma': 3.9957122434407313}. Best is trial 11 with value: 0.67387786389575.\n[I 2025-05-04 04:09:11,475] Trial 32 finished with value: 0.6321416491418992 and parameters: {'learning_rate': 0.0579085851685322, 'max_depth': 4, 'min_child_weight': 9, 'subsample': 0.8383482648676833, 'colsample_bytree': 0.5874188455901299, 'gamma': 4.424774055994303}. Best is trial 11 with value: 0.67387786389575.\n[I 2025-05-04 04:09:16,045] Trial 33 finished with value: 0.6446926262448428 and parameters: {'learning_rate': 0.026555139275530243, 'max_depth': 5, 'min_child_weight': 8, 'subsample': 0.928405831450873, 'colsample_bytree': 0.610242809619141, 'gamma': 3.9493190542470096}. Best is trial 11 with value: 0.67387786389575.\n[I 2025-05-04 04:09:21,895] Trial 34 finished with value: 0.6680270754529165 and parameters: {'learning_rate': 0.011796560816583614, 'max_depth': 6, 'min_child_weight': 9, 'subsample': 0.7337913306084312, 'colsample_bytree': 0.5443827890544898, 'gamma': 4.890919418122754}. Best is trial 11 with value: 0.67387786389575.\n[I 2025-05-04 04:09:27,095] Trial 35 finished with value: 0.6461641520636999 and parameters: {'learning_rate': 0.02988388247307841, 'max_depth': 6, 'min_child_weight': 10, 'subsample': 0.740546164300947, 'colsample_bytree': 0.5359700751074309, 'gamma': 4.964830565672189}. Best is trial 11 with value: 0.67387786389575.\n[I 2025-05-04 04:09:33,619] Trial 36 finished with value: 0.6539762608747517 and parameters: {'learning_rate': 0.054737230119371066, 'max_depth': 8, 'min_child_weight': 6, 'subsample': 0.7164038860845173, 'colsample_bytree': 0.5300212860745164, 'gamma': 4.425237668630345}. Best is trial 11 with value: 0.67387786389575.\n[I 2025-05-04 04:09:44,504] Trial 37 finished with value: 0.6725981911907689 and parameters: {'learning_rate': 0.010637062754863124, 'max_depth': 9, 'min_child_weight': 2, 'subsample': 0.6276689793793203, 'colsample_bytree': 0.6410529421695158, 'gamma': 4.651002587315938}. Best is trial 11 with value: 0.67387786389575.\n[I 2025-05-04 04:09:51,930] Trial 38 finished with value: 0.5462216288384513 and parameters: {'learning_rate': 0.08576247614475006, 'max_depth': 9, 'min_child_weight': 2, 'subsample': 0.6172460017858448, 'colsample_bytree': 0.6441624949347756, 'gamma': 4.988315184178958}. Best is trial 11 with value: 0.67387786389575.\n[I 2025-05-04 04:10:02,061] Trial 39 finished with value: 0.5848675042174419 and parameters: {'learning_rate': 0.04458418600063616, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.6202453005101837, 'colsample_bytree': 0.6633010055311244, 'gamma': 4.658370432470623}. Best is trial 11 with value: 0.67387786389575.\n[I 2025-05-04 04:10:12,151] Trial 40 finished with value: 0.6643261066406985 and parameters: {'learning_rate': 0.027052240059503727, 'max_depth': 9, 'min_child_weight': 4, 'subsample': 0.5695730486422822, 'colsample_bytree': 0.6248058018694399, 'gamma': 4.66321883304891}. Best is trial 11 with value: 0.67387786389575.\n[I 2025-05-04 04:10:17,663] Trial 41 finished with value: 0.6494653828660412 and parameters: {'learning_rate': 0.021094089181476088, 'max_depth': 6, 'min_child_weight': 2, 'subsample': 0.657812891550051, 'colsample_bytree': 0.5680710608336914, 'gamma': 4.235932389496768}. Best is trial 11 with value: 0.67387786389575.\n[I 2025-05-04 04:10:28,296] Trial 42 finished with value: 0.6819692601502102 and parameters: {'learning_rate': 0.011141169284554567, 'max_depth': 10, 'min_child_weight': 10, 'subsample': 0.770168196195663, 'colsample_bytree': 0.5980076206534548, 'gamma': 4.509153333740827}. Best is trial 42 with value: 0.6819692601502102.\n[I 2025-05-04 04:10:37,322] Trial 43 finished with value: 0.5670092914577826 and parameters: {'learning_rate': 0.06513719054284577, 'max_depth': 10, 'min_child_weight': 3, 'subsample': 0.7757165604017684, 'colsample_bytree': 0.7019149006438872, 'gamma': 4.521454412103679}. Best is trial 42 with value: 0.6819692601502102.\n[I 2025-05-04 04:10:45,978] Trial 44 finished with value: 0.570148825612568 and parameters: {'learning_rate': 0.16695178016920006, 'max_depth': 9, 'min_child_weight': 3, 'subsample': 0.7030843058079996, 'colsample_bytree': 0.595299660165196, 'gamma': 4.82182314998288}. Best is trial 42 with value: 0.6819692601502102.\n[I 2025-05-04 04:10:55,471] Trial 45 finished with value: 0.6438061447874992 and parameters: {'learning_rate': 0.03925907943280455, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.7852631228395776, 'colsample_bytree': 0.6317825533345619, 'gamma': 4.581188720747694}. Best is trial 42 with value: 0.6819692601502102.\n[I 2025-05-04 04:11:02,940] Trial 46 finished with value: 0.6607371794871795 and parameters: {'learning_rate': 0.02546537704203433, 'max_depth': 8, 'min_child_weight': 8, 'subsample': 0.5803728588361705, 'colsample_bytree': 0.7640230104143781, 'gamma': 3.793057743144901}. Best is trial 42 with value: 0.6819692601502102.\n[I 2025-05-04 04:11:10,691] Trial 47 finished with value: 0.6500023076568052 and parameters: {'learning_rate': 0.049555181258692446, 'max_depth': 9, 'min_child_weight': 4, 'subsample': 0.5076877544568091, 'colsample_bytree': 0.5183687665444594, 'gamma': 2.418753532851951}. Best is trial 42 with value: 0.6819692601502102.\n[I 2025-05-04 04:11:19,449] Trial 48 finished with value: 0.5112194203103294 and parameters: {'learning_rate': 0.2625182541102677, 'max_depth': 10, 'min_child_weight': 9, 'subsample': 0.6687264372782866, 'colsample_bytree': 0.5010698282940276, 'gamma': 3.5129678950310916}. Best is trial 42 with value: 0.6819692601502102.\n[I 2025-05-04 04:11:24,756] Trial 49 finished with value: 0.6583591882406795 and parameters: {'learning_rate': 0.1289132157748384, 'max_depth': 7, 'min_child_weight': 7, 'subsample': 0.8303026888593397, 'colsample_bytree': 0.5717319241648521, 'gamma': 4.809535670982393}. Best is trial 42 with value: 0.6819692601502102.\n","output_type":"stream"},{"name":"stdout","text":"Best trial:\nFrozenTrial(number=42, state=1, values=[0.6819692601502102], datetime_start=datetime.datetime(2025, 5, 4, 4, 10, 17, 664556), datetime_complete=datetime.datetime(2025, 5, 4, 4, 10, 28, 295777), params={'learning_rate': 0.011141169284554567, 'max_depth': 10, 'min_child_weight': 10, 'subsample': 0.770168196195663, 'colsample_bytree': 0.5980076206534548, 'gamma': 4.509153333740827}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'learning_rate': FloatDistribution(high=0.3, log=False, low=0.01, step=None), 'max_depth': IntDistribution(high=10, log=False, low=3, step=1), 'min_child_weight': IntDistribution(high=10, log=False, low=1, step=1), 'subsample': FloatDistribution(high=1.0, log=False, low=0.5, step=None), 'colsample_bytree': FloatDistribution(high=1.0, log=False, low=0.5, step=None), 'gamma': FloatDistribution(high=5.0, log=False, low=0.0, step=None)}, trial_id=42, value=None)\nBest hyperparameters:\nlearning_rate: 0.011141169284554567\nmax_depth: 10\nmin_child_weight: 10\nsubsample: 0.770168196195663\ncolsample_bytree: 0.5980076206534548\ngamma: 4.509153333740827\n\nClassification report with threshold = 0.7500000000000002:\n              precision    recall  f1-score   support\n\n           0       0.92      0.86      0.89    159566\n           1       0.61      0.76      0.68     47528\n\n    accuracy                           0.83    207094\n   macro avg       0.77      0.81      0.78    207094\nweighted avg       0.85      0.83      0.84    207094\n\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"**Đánh giá:**\n\nLớp mưa:\n* Recall = 0.80: Mô hình phát hiện được 80% các trường hợp có mưa → rất tốt trong bối cảnh nhãn lệch (khó học).\n* F1-score = 0.70: Mức F1-score cao hơn mô hình mặc định (~0.57) hoặc các cấu hình thủ công trước đó.\n* Precision = 0.61: Có một số false positives (dự đoán sai là mưa)\n\nLớp không mưa: Rất tốt, vẫn giữ precision 0.93 và F1-score 0.89\n\n**Không bắt buộc phải cân bằng dữ liệu khi dùng XGBoost vì đã dùng scale_pos_weight, threshold và tham số bằng optuna) nhưng vẫn nên thử**\n\n=> Chọn đặc trưng hay không thì kết quả cũng tương tự nhau.","metadata":{}},{"cell_type":"markdown","source":"# 6. Cân bằng dữ liệu (Oversampling)","metadata":{}},{"cell_type":"markdown","source":"## 6.1 SMOTE","metadata":{}},{"cell_type":"code","source":"# SMOTE\nfrom imblearn.over_sampling import SMOTE\n\nsm = SMOTE()\n\nX_sm, y_sm = sm.fit_resample(X_train, y_train)\nX_sm.shape, y_sm.shape\n\nscaler = MinMaxScaler()\nX_train_scaled = scaler.fit_transform(X_sm)\nX_test_scaled = scaler.transform(X_test)\n\nX_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\nX_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T04:11:41.632168Z","iopub.execute_input":"2025-05-04T04:11:41.632396Z","iopub.status.idle":"2025-05-04T04:11:47.806380Z","shell.execute_reply.started":"2025-05-04T04:11:41.632379Z","shell.execute_reply":"2025-05-04T04:11:47.805434Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"import xgboost as xgb\n\nmodel_xgb = xgb.XGBClassifier(random_state=42, n_estimators = 200)\nmodel_xgb.fit(X_sm, y_sm)\n\ny_pred = model_xgb.predict(X_test)\nprint_scores( y_test, y_pred)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T04:11:47.807613Z","iopub.execute_input":"2025-05-04T04:11:47.807916Z","iopub.status.idle":"2025-05-04T04:12:00.290517Z","shell.execute_reply.started":"2025-05-04T04:11:47.807893Z","shell.execute_reply":"2025-05-04T04:12:00.289445Z"}},"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.89      0.85      0.87    159566\n           1       0.56      0.66      0.61     47528\n\n    accuracy                           0.81    207094\n   macro avg       0.73      0.75      0.74    207094\nweighted avg       0.82      0.81      0.81    207094\n\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"import xgboost as xgb\n\nmodel_xgb = xgb.XGBClassifier(random_state=42, n_estimators = 200)\nmodel_xgb.fit(X_train_scaled, y_sm)\n\ny_pred = model_xgb.predict(X_test_scaled)\nprint_scores( y_test, y_pred)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T04:12:00.291700Z","iopub.execute_input":"2025-05-04T04:12:00.292022Z","iopub.status.idle":"2025-05-04T04:12:12.908028Z","shell.execute_reply.started":"2025-05-04T04:12:00.291995Z","shell.execute_reply":"2025-05-04T04:12:12.906997Z"}},"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.87      0.87      0.87    159566\n           1       0.57      0.58      0.58     47528\n\n    accuracy                           0.80    207094\n   macro avg       0.72      0.72      0.72    207094\nweighted avg       0.80      0.80      0.80    207094\n\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"import xgboost as xgb\n\nmodel_xgb = xgb.XGBClassifier(random_state=42, n_estimators = 200)\nmodel_xgb.fit(X_train_scaled[top_features], y_sm)\n\ny_pred = model_xgb.predict(X_test_scaled[top_features])\nprint_scores( y_test, y_pred)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T04:12:12.909380Z","iopub.execute_input":"2025-05-04T04:12:12.909753Z","iopub.status.idle":"2025-05-04T04:12:22.939225Z","shell.execute_reply.started":"2025-05-04T04:12:12.909717Z","shell.execute_reply":"2025-05-04T04:12:22.938169Z"}},"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.89      0.84      0.86    159566\n           1       0.54      0.65      0.59     47528\n\n    accuracy                           0.79    207094\n   macro avg       0.72      0.74      0.73    207094\nweighted avg       0.81      0.79      0.80    207094\n\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"import xgboost as xgb\n\nmodel_xgb = xgb.XGBClassifier(random_state=42, n_estimators = 200, min_child_weight=5)\nmodel_xgb.fit(X_train_scaled, y_sm)\n\ny_pred = model_xgb.predict(X_test_scaled)\nprint_scores( y_test, y_pred)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T04:12:22.940490Z","iopub.execute_input":"2025-05-04T04:12:22.940844Z","iopub.status.idle":"2025-05-04T04:12:35.118530Z","shell.execute_reply.started":"2025-05-04T04:12:22.940811Z","shell.execute_reply":"2025-05-04T04:12:35.117354Z"}},"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.90      0.85      0.88    159566\n           1       0.58      0.67      0.62     47528\n\n    accuracy                           0.81    207094\n   macro avg       0.74      0.76      0.75    207094\nweighted avg       0.82      0.81      0.82    207094\n\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"=> Thêm min_child_weight có cải thiện","metadata":{}},{"cell_type":"code","source":"import xgboost as xgb\n\nmodel_xgb = xgb.XGBClassifier(random_state=42, n_estimators = 200, scale_pos_weight=11.32)\nmodel_xgb.fit(X_train_scaled, y_sm)\n\ny_pred = model_xgb.predict(X_test_scaled)\nprint_scores( y_test, y_pred)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T04:12:35.119624Z","iopub.execute_input":"2025-05-04T04:12:35.119943Z","iopub.status.idle":"2025-05-04T04:12:48.133536Z","shell.execute_reply.started":"2025-05-04T04:12:35.119912Z","shell.execute_reply":"2025-05-04T04:12:48.132565Z"}},"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.90      0.73      0.81    159566\n           1       0.45      0.73      0.56     47528\n\n    accuracy                           0.73    207094\n   macro avg       0.68      0.73      0.68    207094\nweighted avg       0.80      0.73      0.75    207094\n\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"=> Thêm scale_pos_weight giảm","metadata":{}},{"cell_type":"code","source":"import xgboost as xgb\n\nmodel_xgb = xgb.XGBClassifier(\n    n_estimators=200,\n    max_depth=6,\n    learning_rate=0.1,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    # scale_pos_weight=11.32,\n    random_state=42,\n    min_child_weight=5\n    \n)\n\nmodel_xgb.fit(X_train_scaled, y_sm)\n\ny_pred = model_xgb.predict(X_test_scaled)\nprint_scores(y_test, y_pred)\n\ny_probs = model_xgb.predict_proba(X_test_scaled)[:,1]\n\nbest_thresh = 0.0\nbest_f1 = 0.0\nfor t in np.arange(0.1, 0.9, 0.05):\n    y_pred = (y_probs >= t).astype(int)\n    f1 = f1_score(y_test, y_pred)\n    if f1 > best_f1:\n        best_f1 = f1\n        best_thresh = t\n\nprint(f\"Best threshold: {best_thresh}, F1: {best_f1}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T04:12:48.134581Z","iopub.execute_input":"2025-05-04T04:12:48.134942Z","iopub.status.idle":"2025-05-04T04:13:03.238955Z","shell.execute_reply.started":"2025-05-04T04:12:48.134911Z","shell.execute_reply":"2025-05-04T04:13:03.237914Z"}},"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.93      0.81      0.87    159566\n           1       0.55      0.79      0.65     47528\n\n    accuracy                           0.81    207094\n   macro avg       0.74      0.80      0.76    207094\nweighted avg       0.84      0.81      0.82    207094\n\nBest threshold: 0.5500000000000002, F1: 0.6522934690260636\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"import optuna\nimport numpy as np\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import train_test_split\nimport xgboost as xgb\n\nTHRESHOLD = best_thresh\n# SCALE_POS_WEIGHT = 11.32 \n\ndef objective(trial):\n    # Thử các tham số\n    param = {\n        'n_estimators': 200,\n        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n        'max_depth': trial.suggest_int('max_depth', 3, 10),\n        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n        'gamma': trial.suggest_float('gamma', 0, 5),\n        # 'scale_pos_weight': SCALE_POS_WEIGHT,\n        'random_state': 42,\n        'verbosity': 0,\n        'n_jobs': -1,\n        'use_label_encoder': False,\n        'eval_metric': 'logloss'\n    }\n\n    model = xgb.XGBClassifier(**param)\n    model.fit(X_train_scaled, y_sm)\n\n    # Dự đoán xác suất\n    y_probs = model.predict_proba(X_test_scaled)[:, 1]\n    y_pred = (y_probs >= THRESHOLD).astype(int)\n\n    # Trả về F1-score của lớp mưa (label=1)\n    return f1_score(y_test, y_pred, pos_label=1)\n\n\n# Tối ưu với Optuna\nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=30)  # Có thể tăng trials lên 100+\n\n# In kết quả tốt nhất\nprint(\"Best trial:\")\nprint(study.best_trial)\nprint(\"Best hyperparameters:\")\nfor key, value in study.best_trial.params.items():\n    print(f\"{key}: {value}\")\n\n# Huấn luyện lại với tham số tốt nhất\nbest_params = study.best_trial.params\nbest_params.update({\n    'n_estimators': 200,\n    # 'scale_pos_weight': SCALE_POS_WEIGHT,\n    'random_state': 42,\n    'use_label_encoder': False,\n    'eval_metric': 'logloss'\n})\n\nbest_model = xgb.XGBClassifier(**best_params)\nbest_model.fit(X_train_scaled, y_sm)\n\n# Dự đoán với threshold\ny_probs = best_model.predict_proba(X_test_scaled)[:, 1]\ny_pred_thresh = (y_probs >= THRESHOLD).astype(int)\n\n# In kết quả\nfrom sklearn.metrics import classification_report\nprint(f\"\\nClassification report with threshold = {THRESHOLD}:\")\nprint(classification_report(y_test, y_pred_thresh))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T04:13:03.240028Z","iopub.execute_input":"2025-05-04T04:13:03.240319Z","iopub.status.idle":"2025-05-04T04:20:40.360263Z","shell.execute_reply.started":"2025-05-04T04:13:03.240291Z","shell.execute_reply":"2025-05-04T04:20:40.359512Z"}},"outputs":[{"name":"stderr","text":"[I 2025-05-04 04:13:03,248] A new study created in memory with name: no-name-d52f9b2d-1e12-43dd-bd17-36608483284d\n[I 2025-05-04 04:13:20,637] Trial 0 finished with value: 0.6062899920538664 and parameters: {'learning_rate': 0.11062457482259704, 'max_depth': 9, 'min_child_weight': 5, 'subsample': 0.9975969928966021, 'colsample_bytree': 0.877056036092343, 'gamma': 2.9717146301115527}. Best is trial 0 with value: 0.6062899920538664.\n[I 2025-05-04 04:13:34,869] Trial 1 finished with value: 0.6555413388506247 and parameters: {'learning_rate': 0.09190919201932185, 'max_depth': 7, 'min_child_weight': 1, 'subsample': 0.9775060773980844, 'colsample_bytree': 0.5633930057326808, 'gamma': 4.945860882234348}. Best is trial 1 with value: 0.6555413388506247.\n[I 2025-05-04 04:13:52,323] Trial 2 finished with value: 0.5619798761432708 and parameters: {'learning_rate': 0.17655065310260842, 'max_depth': 9, 'min_child_weight': 5, 'subsample': 0.673222961066432, 'colsample_bytree': 0.9909510445868477, 'gamma': 2.519798365462817}. Best is trial 1 with value: 0.6555413388506247.\n[I 2025-05-04 04:14:06,116] Trial 3 finished with value: 0.5713477892081167 and parameters: {'learning_rate': 0.24654838120889797, 'max_depth': 7, 'min_child_weight': 6, 'subsample': 0.7526999437047446, 'colsample_bytree': 0.5661046769249631, 'gamma': 2.9659417872025644}. Best is trial 1 with value: 0.6555413388506247.\n[I 2025-05-04 04:14:16,152] Trial 4 finished with value: 0.6373823963155446 and parameters: {'learning_rate': 0.05925786646381777, 'max_depth': 4, 'min_child_weight': 8, 'subsample': 0.8814488852116684, 'colsample_bytree': 0.9196569336565652, 'gamma': 1.9757797545449414}. Best is trial 1 with value: 0.6555413388506247.\n[I 2025-05-04 04:14:32,218] Trial 5 finished with value: 0.6521893847459329 and parameters: {'learning_rate': 0.07374317187661546, 'max_depth': 7, 'min_child_weight': 1, 'subsample': 0.7051248126894062, 'colsample_bytree': 0.9354597573812653, 'gamma': 3.4722312468107406}. Best is trial 1 with value: 0.6555413388506247.\n[I 2025-05-04 04:14:44,471] Trial 6 finished with value: 0.6474791621435381 and parameters: {'learning_rate': 0.12617841143929578, 'max_depth': 6, 'min_child_weight': 6, 'subsample': 0.9027824439223979, 'colsample_bytree': 0.6222068586244165, 'gamma': 0.032407861783259606}. Best is trial 1 with value: 0.6555413388506247.\n[I 2025-05-04 04:14:53,365] Trial 7 finished with value: 0.6460333924448757 and parameters: {'learning_rate': 0.19241670124231597, 'max_depth': 3, 'min_child_weight': 3, 'subsample': 0.5435577256516014, 'colsample_bytree': 0.9894246481514221, 'gamma': 3.838033201789443}. Best is trial 1 with value: 0.6555413388506247.\n[I 2025-05-04 04:15:09,537] Trial 8 finished with value: 0.6160944921256563 and parameters: {'learning_rate': 0.26865868610104277, 'max_depth': 8, 'min_child_weight': 8, 'subsample': 0.5520610938810218, 'colsample_bytree': 0.8373848206149932, 'gamma': 4.081502160826009}. Best is trial 1 with value: 0.6555413388506247.\n[I 2025-05-04 04:15:23,973] Trial 9 finished with value: 0.6151267423395872 and parameters: {'learning_rate': 0.017570057387382522, 'max_depth': 6, 'min_child_weight': 4, 'subsample': 0.8322485803838711, 'colsample_bytree': 0.998318317411024, 'gamma': 0.7522078339252364}. Best is trial 1 with value: 0.6555413388506247.\n[I 2025-05-04 04:15:50,899] Trial 10 finished with value: 0.6309668610171619 and parameters: {'learning_rate': 0.018849812858314385, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.9888061990688403, 'colsample_bytree': 0.6865800430375587, 'gamma': 4.94425268732905}. Best is trial 1 with value: 0.6555413388506247.\n[I 2025-05-04 04:16:03,780] Trial 11 finished with value: 0.6443545482717322 and parameters: {'learning_rate': 0.08347034214885563, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6736477497515747, 'colsample_bytree': 0.5051662636303405, 'gamma': 4.999786503394235}. Best is trial 1 with value: 0.6555413388506247.\n[I 2025-05-04 04:16:18,014] Trial 12 finished with value: 0.6451509083106851 and parameters: {'learning_rate': 0.0657232724216682, 'max_depth': 7, 'min_child_weight': 2, 'subsample': 0.7362263625874377, 'colsample_bytree': 0.7773860923202042, 'gamma': 3.9867850239115774}. Best is trial 1 with value: 0.6555413388506247.\n[I 2025-05-04 04:16:33,410] Trial 13 finished with value: 0.6196894167846226 and parameters: {'learning_rate': 0.13789298912181575, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.6211554048993475, 'colsample_bytree': 0.7360657322069111, 'gamma': 1.7082622711445152}. Best is trial 1 with value: 0.6555413388506247.\n[I 2025-05-04 04:16:45,042] Trial 14 finished with value: 0.648133010862329 and parameters: {'learning_rate': 0.09479728247394043, 'max_depth': 5, 'min_child_weight': 10, 'subsample': 0.7867417457417627, 'colsample_bytree': 0.6541107778248905, 'gamma': 3.485727198004457}. Best is trial 1 with value: 0.6555413388506247.\n[I 2025-05-04 04:17:01,819] Trial 15 finished with value: 0.6478628426957416 and parameters: {'learning_rate': 0.04699436264068793, 'max_depth': 8, 'min_child_weight': 1, 'subsample': 0.9326674061240927, 'colsample_bytree': 0.7643796232169996, 'gamma': 4.5149147663034395}. Best is trial 1 with value: 0.6555413388506247.\n[I 2025-05-04 04:17:14,305] Trial 16 finished with value: 0.6504352532587614 and parameters: {'learning_rate': 0.16576971380117517, 'max_depth': 5, 'min_child_weight': 2, 'subsample': 0.8368813983603719, 'colsample_bytree': 0.5825420656915162, 'gamma': 3.281823503700312}. Best is trial 1 with value: 0.6555413388506247.\n[I 2025-05-04 04:17:28,173] Trial 17 finished with value: 0.6049762835982359 and parameters: {'learning_rate': 0.2117521601962766, 'max_depth': 7, 'min_child_weight': 3, 'subsample': 0.6734229309686312, 'colsample_bytree': 0.5094833027842363, 'gamma': 4.376815794138821}. Best is trial 1 with value: 0.6555413388506247.\n[I 2025-05-04 04:17:42,259] Trial 18 finished with value: 0.6454039023206771 and parameters: {'learning_rate': 0.14639540501607523, 'max_depth': 6, 'min_child_weight': 2, 'subsample': 0.6068565344493214, 'colsample_bytree': 0.8327064130745194, 'gamma': 1.870671337343852}. Best is trial 1 with value: 0.6555413388506247.\n[I 2025-05-04 04:18:01,970] Trial 19 finished with value: 0.5969308862892303 and parameters: {'learning_rate': 0.09490748380917721, 'max_depth': 10, 'min_child_weight': 4, 'subsample': 0.7298566091658254, 'colsample_bytree': 0.7124662519021345, 'gamma': 4.538331796757663}. Best is trial 1 with value: 0.6555413388506247.\n[I 2025-05-04 04:18:23,064] Trial 20 finished with value: 0.6419537723506323 and parameters: {'learning_rate': 0.03864083827995141, 'max_depth': 9, 'min_child_weight': 7, 'subsample': 0.5014418036154445, 'colsample_bytree': 0.9131897467958886, 'gamma': 2.4346238874957025}. Best is trial 1 with value: 0.6555413388506247.\n[I 2025-05-04 04:18:34,254] Trial 21 finished with value: 0.6501454565166326 and parameters: {'learning_rate': 0.17194822967134116, 'max_depth': 5, 'min_child_weight': 2, 'subsample': 0.8546897764318057, 'colsample_bytree': 0.5983311485792524, 'gamma': 3.237365285044849}. Best is trial 1 with value: 0.6555413388506247.\n[I 2025-05-04 04:18:45,407] Trial 22 finished with value: 0.6447062667925351 and parameters: {'learning_rate': 0.21188552952732614, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.7970588696809153, 'colsample_bytree': 0.5578434234260516, 'gamma': 3.5687300718734827}. Best is trial 1 with value: 0.6555413388506247.\n[I 2025-05-04 04:18:57,468] Trial 23 finished with value: 0.6519727988164099 and parameters: {'learning_rate': 0.11984355577776995, 'max_depth': 6, 'min_child_weight': 2, 'subsample': 0.9349625669052744, 'colsample_bytree': 0.5568801728177818, 'gamma': 2.4977731344743277}. Best is trial 1 with value: 0.6555413388506247.\n[I 2025-05-04 04:19:11,541] Trial 24 finished with value: 0.6352961863082213 and parameters: {'learning_rate': 0.11856480736746512, 'max_depth': 7, 'min_child_weight': 1, 'subsample': 0.9342260330284557, 'colsample_bytree': 0.6585787068330564, 'gamma': 1.2501423497672217}. Best is trial 1 with value: 0.6555413388506247.\n[I 2025-05-04 04:19:25,640] Trial 25 finished with value: 0.6438949827605672 and parameters: {'learning_rate': 0.07717038460070527, 'max_depth': 6, 'min_child_weight': 4, 'subsample': 0.9475889572696363, 'colsample_bytree': 0.5278982706211892, 'gamma': 2.5900671823126675}. Best is trial 1 with value: 0.6555413388506247.\n[I 2025-05-04 04:19:40,959] Trial 26 finished with value: 0.6404893255056987 and parameters: {'learning_rate': 0.1064684484990004, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.9629585648707081, 'colsample_bytree': 0.6259767902992588, 'gamma': 2.2109032406680265}. Best is trial 1 with value: 0.6555413388506247.\n[I 2025-05-04 04:19:55,925] Trial 27 finished with value: 0.6259061522838557 and parameters: {'learning_rate': 0.13802530259170404, 'max_depth': 7, 'min_child_weight': 2, 'subsample': 0.9181832235381064, 'colsample_bytree': 0.7908195324495274, 'gamma': 1.536566168420918}. Best is trial 1 with value: 0.6555413388506247.\n[I 2025-05-04 04:20:09,431] Trial 28 finished with value: 0.6344122328879457 and parameters: {'learning_rate': 0.04134014986957938, 'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.8818548241647888, 'colsample_bytree': 0.9459217591027156, 'gamma': 2.789838157866663}. Best is trial 1 with value: 0.6555413388506247.\n[I 2025-05-04 04:20:26,545] Trial 29 finished with value: 0.6297573691598155 and parameters: {'learning_rate': 0.1103470877358323, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.9785966633068359, 'colsample_bytree': 0.8343779131390539, 'gamma': 1.2612740330802543}. Best is trial 1 with value: 0.6555413388506247.\n","output_type":"stream"},{"name":"stdout","text":"Best trial:\nFrozenTrial(number=1, state=1, values=[0.6555413388506247], datetime_start=datetime.datetime(2025, 5, 4, 4, 13, 20, 638281), datetime_complete=datetime.datetime(2025, 5, 4, 4, 13, 34, 869321), params={'learning_rate': 0.09190919201932185, 'max_depth': 7, 'min_child_weight': 1, 'subsample': 0.9775060773980844, 'colsample_bytree': 0.5633930057326808, 'gamma': 4.945860882234348}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'learning_rate': FloatDistribution(high=0.3, log=False, low=0.01, step=None), 'max_depth': IntDistribution(high=10, log=False, low=3, step=1), 'min_child_weight': IntDistribution(high=10, log=False, low=1, step=1), 'subsample': FloatDistribution(high=1.0, log=False, low=0.5, step=None), 'colsample_bytree': FloatDistribution(high=1.0, log=False, low=0.5, step=None), 'gamma': FloatDistribution(high=5.0, log=False, low=0.0, step=None)}, trial_id=1, value=None)\nBest hyperparameters:\nlearning_rate: 0.09190919201932185\nmax_depth: 7\nmin_child_weight: 1\nsubsample: 0.9775060773980844\ncolsample_bytree: 0.5633930057326808\ngamma: 4.945860882234348\n\nClassification report with threshold = 0.5500000000000002:\n              precision    recall  f1-score   support\n\n           0       0.92      0.83      0.88    159566\n           1       0.58      0.76      0.66     47528\n\n    accuracy                           0.82    207094\n   macro avg       0.75      0.80      0.77    207094\nweighted avg       0.84      0.82      0.82    207094\n\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"import xgboost as xgb\n\nmodel_xgb = xgb.XGBClassifier(\n    n_estimators=200,\n    max_depth=6,\n    learning_rate=0.1,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    # scale_pos_weight=11.32,\n    random_state=42,\n    min_child_weight=5\n    \n)\n\nmodel_xgb.fit(X_train_scaled[top_features], y_sm)\n\ny_pred = model_xgb.predict(X_test_scaled[top_features])\nprint_scores(y_test, y_pred)\n\ny_probs = model_xgb.predict_proba(X_test_scaled[top_features])[:,1]\n\nbest_thresh = 0.0\nbest_f1 = 0.0\nfor t in np.arange(0.1, 0.9, 0.05):\n    y_pred = (y_probs >= t).astype(int)\n    f1 = f1_score(y_test, y_pred)\n    if f1 > best_f1:\n        best_f1 = f1\n        best_thresh = t\n\nprint(f\"Best threshold: {best_thresh}, F1: {best_f1}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T04:20:40.361064Z","iopub.execute_input":"2025-05-04T04:20:40.361301Z","iopub.status.idle":"2025-05-04T04:20:50.772079Z","shell.execute_reply.started":"2025-05-04T04:20:40.361284Z","shell.execute_reply":"2025-05-04T04:20:50.771140Z"}},"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.93      0.77      0.84    159566\n           1       0.51      0.79      0.62     47528\n\n    accuracy                           0.78    207094\n   macro avg       0.72      0.78      0.73    207094\nweighted avg       0.83      0.78      0.79    207094\n\nBest threshold: 0.5500000000000002, F1: 0.6221290384065569\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"import optuna\nimport numpy as np\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import train_test_split\nimport xgboost as xgb\n\n\nTHRESHOLD = best_thresh\n# SCALE_POS_WEIGHT = 11.32 \n\ndef objective(trial):\n    # Thử các tham số\n    param = {\n        'n_estimators': 200,\n        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n        'max_depth': trial.suggest_int('max_depth', 3, 10),\n        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n        'gamma': trial.suggest_float('gamma', 0, 5),\n        # 'scale_pos_weight': SCALE_POS_WEIGHT,\n        'random_state': 42,\n        'verbosity': 0,\n        'n_jobs': -1,\n        'use_label_encoder': False,\n        'eval_metric': 'logloss'\n    }\n\n    model = xgb.XGBClassifier(**param)\n    model.fit(X_train_scaled[top_features], y_sm)\n\n    # Dự đoán xác suất\n    y_probs = model.predict_proba(X_test_scaled[top_features])[:, 1]\n    y_pred = (y_probs >= THRESHOLD).astype(int)\n\n    # Trả về F1-score của lớp mưa (label=1)\n    return f1_score(y_test, y_pred, pos_label=1)\n\n\n# Tối ưu với Optuna\nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=30)  # Có thể tăng trials lên 100+\n\n# In kết quả tốt nhất\nprint(\"Best trial:\")\nprint(study.best_trial)\nprint(\"Best hyperparameters:\")\nfor key, value in study.best_trial.params.items():\n    print(f\"{key}: {value}\")\n\n# Huấn luyện lại với tham số tốt nhất\nbest_params = study.best_trial.params\nbest_params.update({\n    'n_estimators': 200,\n    # 'scale_pos_weight': SCALE_POS_WEIGHT,\n    'random_state': 42,\n    'use_label_encoder': False,\n    'eval_metric': 'logloss'\n})\n\nbest_model = xgb.XGBClassifier(**best_params)\nbest_model.fit(X_train_scaled[top_features], y_sm)\n\n# Dự đoán với threshold\ny_probs = best_model.predict_proba(X_test_scaled[top_features])[:, 1]\ny_pred_thresh = (y_probs >= THRESHOLD).astype(int)\n\n# In kết quả\nfrom sklearn.metrics import classification_report\nprint(f\"\\nClassification report with threshold = {THRESHOLD}:\")\nprint(classification_report(y_test, y_pred_thresh))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T04:20:50.777209Z","iopub.execute_input":"2025-05-04T04:20:50.777549Z","iopub.status.idle":"2025-05-04T04:25:32.791488Z","shell.execute_reply.started":"2025-05-04T04:20:50.777515Z","shell.execute_reply":"2025-05-04T04:25:32.790632Z"}},"outputs":[{"name":"stderr","text":"[I 2025-05-04 04:20:50,786] A new study created in memory with name: no-name-625cde8b-b432-4fab-af4e-dac9cf0e937f\n[I 2025-05-04 04:20:57,934] Trial 0 finished with value: 0.6243075821186653 and parameters: {'learning_rate': 0.069851239162954, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.9570542853394668, 'colsample_bytree': 0.9948635984206922, 'gamma': 3.3253010977094166}. Best is trial 0 with value: 0.6243075821186653.\n[I 2025-05-04 04:21:09,721] Trial 1 finished with value: 0.49735637801572846 and parameters: {'learning_rate': 0.17663118151584933, 'max_depth': 9, 'min_child_weight': 10, 'subsample': 0.8683556718337033, 'colsample_bytree': 0.7019010949541067, 'gamma': 0.6815190847116609}. Best is trial 0 with value: 0.6243075821186653.\n[I 2025-05-04 04:21:16,383] Trial 2 finished with value: 0.5902333732551136 and parameters: {'learning_rate': 0.011253036969929795, 'max_depth': 3, 'min_child_weight': 10, 'subsample': 0.529323343362218, 'colsample_bytree': 0.8695413804868146, 'gamma': 3.6814390106130284}. Best is trial 0 with value: 0.6243075821186653.\n[I 2025-05-04 04:21:22,448] Trial 3 finished with value: 0.6130452957510973 and parameters: {'learning_rate': 0.10301058539700288, 'max_depth': 3, 'min_child_weight': 9, 'subsample': 0.7078655137443743, 'colsample_bytree': 0.7139708799079176, 'gamma': 3.1034702107437733}. Best is trial 0 with value: 0.6243075821186653.\n[I 2025-05-04 04:21:34,641] Trial 4 finished with value: 0.5419502729658264 and parameters: {'learning_rate': 0.14092376339401536, 'max_depth': 8, 'min_child_weight': 5, 'subsample': 0.5134968041242629, 'colsample_bytree': 0.959684014564637, 'gamma': 1.1310308888908804}. Best is trial 0 with value: 0.6243075821186653.\n[I 2025-05-04 04:21:46,852] Trial 5 finished with value: 0.4443191164375514 and parameters: {'learning_rate': 0.22950767290694984, 'max_depth': 9, 'min_child_weight': 5, 'subsample': 0.5184259990531523, 'colsample_bytree': 0.8370452008365828, 'gamma': 2.09879061500031}. Best is trial 0 with value: 0.6243075821186653.\n[I 2025-05-04 04:21:55,434] Trial 6 finished with value: 0.5360828854342211 and parameters: {'learning_rate': 0.20348918985651998, 'max_depth': 6, 'min_child_weight': 7, 'subsample': 0.6778838267960897, 'colsample_bytree': 0.7465388416747071, 'gamma': 1.4772148588769212}. Best is trial 0 with value: 0.6243075821186653.\n[I 2025-05-04 04:22:03,217] Trial 7 finished with value: 0.615451187661304 and parameters: {'learning_rate': 0.061485622678185824, 'max_depth': 4, 'min_child_weight': 10, 'subsample': 0.6224856824275349, 'colsample_bytree': 0.7875461539164255, 'gamma': 1.2964472778259528}. Best is trial 0 with value: 0.6243075821186653.\n[I 2025-05-04 04:22:14,026] Trial 8 finished with value: 0.5162339760853173 and parameters: {'learning_rate': 0.15925151995010853, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.8626022104604658, 'colsample_bytree': 0.7754037549129819, 'gamma': 1.201686784723766}. Best is trial 0 with value: 0.6243075821186653.\n[I 2025-05-04 04:22:23,412] Trial 9 finished with value: 0.4968486015669453 and parameters: {'learning_rate': 0.24803828372284878, 'max_depth': 7, 'min_child_weight': 3, 'subsample': 0.575638875392611, 'colsample_bytree': 0.6055579569838025, 'gamma': 3.7111197990583604}. Best is trial 0 with value: 0.6243075821186653.\n[I 2025-05-04 04:22:32,520] Trial 10 finished with value: 0.6220850009529255 and parameters: {'learning_rate': 0.05077428443458813, 'max_depth': 5, 'min_child_weight': 7, 'subsample': 0.9796992515230452, 'colsample_bytree': 0.9799903449552462, 'gamma': 4.319066817148941}. Best is trial 0 with value: 0.6243075821186653.\n[I 2025-05-04 04:22:40,228] Trial 11 finished with value: 0.6169534347485294 and parameters: {'learning_rate': 0.04871670661989395, 'max_depth': 5, 'min_child_weight': 7, 'subsample': 0.9782807527262176, 'colsample_bytree': 0.97741935885806, 'gamma': 4.96750262571179}. Best is trial 0 with value: 0.6243075821186653.\n[I 2025-05-04 04:22:47,681] Trial 12 finished with value: 0.6317770293735211 and parameters: {'learning_rate': 0.0963959736180563, 'max_depth': 5, 'min_child_weight': 7, 'subsample': 0.9919069270941059, 'colsample_bytree': 0.9159819550766892, 'gamma': 4.908445434117468}. Best is trial 12 with value: 0.6317770293735211.\n[I 2025-05-04 04:22:55,099] Trial 13 finished with value: 0.5822855224667914 and parameters: {'learning_rate': 0.2959930572928444, 'max_depth': 5, 'min_child_weight': 8, 'subsample': 0.8645186361340076, 'colsample_bytree': 0.9008298141836936, 'gamma': 2.6229713522121827}. Best is trial 12 with value: 0.6317770293735211.\n[I 2025-05-04 04:23:03,307] Trial 14 finished with value: 0.6181053729946216 and parameters: {'learning_rate': 0.10526931071479984, 'max_depth': 4, 'min_child_weight': 6, 'subsample': 0.9217525674964594, 'colsample_bytree': 0.9144916586100788, 'gamma': 4.960906466810497}. Best is trial 12 with value: 0.6317770293735211.\n[I 2025-05-04 04:23:11,843] Trial 15 finished with value: 0.6364667273758182 and parameters: {'learning_rate': 0.10897418069897816, 'max_depth': 6, 'min_child_weight': 4, 'subsample': 0.7984487060260363, 'colsample_bytree': 0.592385534450679, 'gamma': 4.082380111470863}. Best is trial 15 with value: 0.6364667273758182.\n[I 2025-05-04 04:23:20,326] Trial 16 finished with value: 0.5972405868996271 and parameters: {'learning_rate': 0.11613112357047572, 'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.78328342537036, 'colsample_bytree': 0.5195072351386907, 'gamma': 4.30955711068499}. Best is trial 15 with value: 0.6364667273758182.\n[I 2025-05-04 04:23:29,742] Trial 17 finished with value: 0.546586608809728 and parameters: {'learning_rate': 0.13009867524514063, 'max_depth': 7, 'min_child_weight': 3, 'subsample': 0.7867969116132864, 'colsample_bytree': 0.6380879617141154, 'gamma': 4.304654337582942}. Best is trial 15 with value: 0.6364667273758182.\n[I 2025-05-04 04:23:39,826] Trial 18 finished with value: 0.6318227490250174 and parameters: {'learning_rate': 0.08708378030524153, 'max_depth': 6, 'min_child_weight': 4, 'subsample': 0.794709457433267, 'colsample_bytree': 0.5063599094256703, 'gamma': 4.38107573039578}. Best is trial 15 with value: 0.6364667273758182.\n[I 2025-05-04 04:23:55,159] Trial 19 finished with value: 0.6118678464161053 and parameters: {'learning_rate': 0.02660422719218858, 'max_depth': 10, 'min_child_weight': 4, 'subsample': 0.7596609985316782, 'colsample_bytree': 0.5129096218723594, 'gamma': 2.5614471298661456}. Best is trial 15 with value: 0.6364667273758182.\n[I 2025-05-04 04:24:03,903] Trial 20 finished with value: 0.61715127102867 and parameters: {'learning_rate': 0.07756886824442605, 'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.8095235839142496, 'colsample_bytree': 0.5639287234579484, 'gamma': 3.9307706622664282}. Best is trial 15 with value: 0.6364667273758182.\n[I 2025-05-04 04:24:14,221] Trial 21 finished with value: 0.5898611523611523 and parameters: {'learning_rate': 0.09132695711100541, 'max_depth': 7, 'min_child_weight': 4, 'subsample': 0.7105338589961095, 'colsample_bytree': 0.6141244708847772, 'gamma': 4.63102709611611}. Best is trial 15 with value: 0.6364667273758182.\n[I 2025-05-04 04:24:21,636] Trial 22 finished with value: 0.6046707079377001 and parameters: {'learning_rate': 0.16150417943435075, 'max_depth': 5, 'min_child_weight': 4, 'subsample': 0.8274671770871519, 'colsample_bytree': 0.5523310398732547, 'gamma': 3.118764244499094}. Best is trial 15 with value: 0.6364667273758182.\n[I 2025-05-04 04:24:30,080] Trial 23 finished with value: 0.5981009143745604 and parameters: {'learning_rate': 0.12784295041873345, 'max_depth': 6, 'min_child_weight': 2, 'subsample': 0.9143807156801774, 'colsample_bytree': 0.6573518063943393, 'gamma': 4.655561736299751}. Best is trial 15 with value: 0.6364667273758182.\n[I 2025-05-04 04:24:39,300] Trial 24 finished with value: 0.6229523977602721 and parameters: {'learning_rate': 0.0817600314093465, 'max_depth': 5, 'min_child_weight': 6, 'subsample': 0.6409680441636094, 'colsample_bytree': 0.57062183867788, 'gamma': 3.9335067386158538}. Best is trial 15 with value: 0.6364667273758182.\n[I 2025-05-04 04:24:51,137] Trial 25 finished with value: 0.618451934875524 and parameters: {'learning_rate': 0.040335769483224024, 'max_depth': 8, 'min_child_weight': 5, 'subsample': 0.7322629394894811, 'colsample_bytree': 0.822239762632166, 'gamma': 0.012744578390970318}. Best is trial 15 with value: 0.6364667273758182.\n[I 2025-05-04 04:25:00,394] Trial 26 finished with value: 0.5092074868849982 and parameters: {'learning_rate': 0.18246776721133195, 'max_depth': 7, 'min_child_weight': 8, 'subsample': 0.9179723941253407, 'colsample_bytree': 0.6753910909102014, 'gamma': 4.529122479339121}. Best is trial 15 with value: 0.6364667273758182.\n[I 2025-05-04 04:25:07,089] Trial 27 finished with value: 0.6185128983308044 and parameters: {'learning_rate': 0.09655799759350804, 'max_depth': 4, 'min_child_weight': 2, 'subsample': 0.8223684207113561, 'colsample_bytree': 0.511815254812167, 'gamma': 4.016749548616894}. Best is trial 15 with value: 0.6364667273758182.\n[I 2025-05-04 04:25:16,586] Trial 28 finished with value: 0.6150000905583831 and parameters: {'learning_rate': 0.14275492412735408, 'max_depth': 6, 'min_child_weight': 6, 'subsample': 0.8980514370372907, 'colsample_bytree': 0.593741852559619, 'gamma': 3.4220162521600987}. Best is trial 15 with value: 0.6364667273758182.\n[I 2025-05-04 04:25:24,109] Trial 29 finished with value: 0.622621173619907 and parameters: {'learning_rate': 0.0734137449572653, 'max_depth': 5, 'min_child_weight': 8, 'subsample': 0.9982088587556743, 'colsample_bytree': 0.9279381218759347, 'gamma': 4.963964366193803}. Best is trial 15 with value: 0.6364667273758182.\n","output_type":"stream"},{"name":"stdout","text":"Best trial:\nFrozenTrial(number=15, state=1, values=[0.6364667273758182], datetime_start=datetime.datetime(2025, 5, 4, 4, 23, 3, 308004), datetime_complete=datetime.datetime(2025, 5, 4, 4, 23, 11, 843284), params={'learning_rate': 0.10897418069897816, 'max_depth': 6, 'min_child_weight': 4, 'subsample': 0.7984487060260363, 'colsample_bytree': 0.592385534450679, 'gamma': 4.082380111470863}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'learning_rate': FloatDistribution(high=0.3, log=False, low=0.01, step=None), 'max_depth': IntDistribution(high=10, log=False, low=3, step=1), 'min_child_weight': IntDistribution(high=10, log=False, low=1, step=1), 'subsample': FloatDistribution(high=1.0, log=False, low=0.5, step=None), 'colsample_bytree': FloatDistribution(high=1.0, log=False, low=0.5, step=None), 'gamma': FloatDistribution(high=5.0, log=False, low=0.0, step=None)}, trial_id=15, value=None)\nBest hyperparameters:\nlearning_rate: 0.10897418069897816\nmax_depth: 6\nmin_child_weight: 4\nsubsample: 0.7984487060260363\ncolsample_bytree: 0.592385534450679\ngamma: 4.082380111470863\n\nClassification report with threshold = 0.5500000000000002:\n              precision    recall  f1-score   support\n\n           0       0.92      0.80      0.86    159566\n           1       0.54      0.78      0.64     47528\n\n    accuracy                           0.80    207094\n   macro avg       0.73      0.79      0.75    207094\nweighted avg       0.84      0.80      0.81    207094\n\n","output_type":"stream"}],"execution_count":28},{"cell_type":"markdown","source":"**Đối với dùng SMOTE:** chỉ scale cao hơn scale xong chọn đặc trưng nhưng không SMOTE cao hơn đã SMOTE.","metadata":{}},{"cell_type":"markdown","source":"## 6.2 SMOTE ENN","metadata":{}},{"cell_type":"code","source":"# SMOTE ENN\nfrom imblearn.combine import SMOTEENN\n\nsmenn = SMOTEENN()\n\nX_smenn, y_smenn = smenn.fit_resample(X_train, y_train)\nX_smenn.shape, y_sm.shape\n\nscaler = MinMaxScaler()\nX_train_scaled = scaler.fit_transform(X_smenn)\nX_test_scaled = scaler.transform(X_test)\n\nX_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\nX_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T04:25:32.792389Z","iopub.execute_input":"2025-05-04T04:25:32.792648Z","iopub.status.idle":"2025-05-04T04:52:59.803832Z","shell.execute_reply.started":"2025-05-04T04:25:32.792630Z","shell.execute_reply":"2025-05-04T04:52:59.802723Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"import xgboost as xgb\n\nmodel_xgb = xgb.XGBClassifier(random_state=42, n_estimators = 200)\nmodel_xgb.fit(X_smenn, y_smenn)\n\ny_pred = model_xgb.predict(X_test)\nprint_scores(y_test, y_pred)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T04:52:59.805417Z","iopub.execute_input":"2025-05-04T04:52:59.805770Z","iopub.status.idle":"2025-05-04T04:53:10.368186Z","shell.execute_reply.started":"2025-05-04T04:52:59.805746Z","shell.execute_reply":"2025-05-04T04:53:10.366918Z"}},"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.90      0.84      0.87    159566\n           1       0.55      0.68      0.61     47528\n\n    accuracy                           0.80    207094\n   macro avg       0.73      0.76      0.74    207094\nweighted avg       0.82      0.80      0.81    207094\n\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"import xgboost as xgb\n\nmodel_xgb = xgb.XGBClassifier(random_state=42, n_estimators = 200)\nmodel_xgb.fit(X_train_scaled, y_smenn)\n\ny_pred = model_xgb.predict(X_test_scaled)\nprint_scores(y_test, y_pred)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T04:53:10.369744Z","iopub.execute_input":"2025-05-04T04:53:10.370181Z","iopub.status.idle":"2025-05-04T04:53:21.878326Z","shell.execute_reply.started":"2025-05-04T04:53:10.370152Z","shell.execute_reply":"2025-05-04T04:53:21.877410Z"}},"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.91      0.83      0.87    159566\n           1       0.56      0.71      0.63     47528\n\n    accuracy                           0.81    207094\n   macro avg       0.73      0.77      0.75    207094\nweighted avg       0.83      0.81      0.81    207094\n\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"import xgboost as xgb\n\nmodel_xgb = xgb.XGBClassifier(random_state=42, n_estimators = 200)\nmodel_xgb.fit(X_train_scaled[top_features], y_smenn)\n\ny_pred = model_xgb.predict(X_test_scaled[top_features])\nprint_scores(y_test, y_pred)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T04:53:21.879345Z","iopub.execute_input":"2025-05-04T04:53:21.879648Z","iopub.status.idle":"2025-05-04T04:53:29.085215Z","shell.execute_reply.started":"2025-05-04T04:53:21.879624Z","shell.execute_reply":"2025-05-04T04:53:29.084502Z"}},"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.89      0.81      0.85    159566\n           1       0.51      0.68      0.58     47528\n\n    accuracy                           0.78    207094\n   macro avg       0.70      0.74      0.71    207094\nweighted avg       0.80      0.78      0.79    207094\n\n","output_type":"stream"}],"execution_count":32},{"cell_type":"markdown","source":"=> Không chọn đặc trưng, scale hay không cũng như nhau.","metadata":{}},{"cell_type":"code","source":"import xgboost as xgb\n\nmodel_xgb = xgb.XGBClassifier(random_state=42, n_estimators = 200, min_child_weight=5)\nmodel_xgb.fit(X_train_scaled, y_smenn)\n\ny_pred = model_xgb.predict(X_test_scaled)\nprint_scores(y_test, y_pred)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T04:53:29.085797Z","iopub.execute_input":"2025-05-04T04:53:29.085998Z","iopub.status.idle":"2025-05-04T04:53:39.149616Z","shell.execute_reply.started":"2025-05-04T04:53:29.085981Z","shell.execute_reply":"2025-05-04T04:53:39.148588Z"}},"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.90      0.83      0.86    159566\n           1       0.55      0.70      0.62     47528\n\n    accuracy                           0.80    207094\n   macro avg       0.73      0.77      0.74    207094\nweighted avg       0.82      0.80      0.81    207094\n\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"import xgboost as xgb\n\nmodel_xgb = xgb.XGBClassifier(\n    n_estimators=200,\n    max_depth=6,\n    learning_rate=0.1,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    # scale_pos_weight=11.32,\n    random_state=42\n)\nmodel_xgb.fit(X_train_scaled, y_smenn)\n\ny_pred = model_xgb.predict(X_test_scaled)\nprint_scores( y_test, y_pred)\n\ny_probs = model_xgb.predict_proba(X_test_scaled)[:,1]\n\nbest_thresh = 0.0\nbest_f1 = 0.0\nfor t in np.arange(0.1, 0.9, 0.05):\n    y_pred = (y_probs >= t).astype(int)\n    f1 = f1_score(y_test, y_pred)\n    if f1 > best_f1:\n        best_f1 = f1\n        best_thresh = t\n\nprint(f\"Best threshold: {best_thresh}, F1: {best_f1}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T04:53:39.150617Z","iopub.execute_input":"2025-05-04T04:53:39.150855Z","iopub.status.idle":"2025-05-04T04:53:52.761310Z","shell.execute_reply.started":"2025-05-04T04:53:39.150837Z","shell.execute_reply":"2025-05-04T04:53:52.760297Z"}},"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.95      0.76      0.84    159566\n           1       0.52      0.86      0.64     47528\n\n    accuracy                           0.78    207094\n   macro avg       0.73      0.81      0.74    207094\nweighted avg       0.85      0.78      0.80    207094\n\nBest threshold: 0.7000000000000002, F1: 0.6607958855197676\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"import optuna\nimport numpy as np\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import train_test_split\nimport xgboost as xgb\n\nTHRESHOLD = best_thresh\n# SCALE_POS_WEIGHT = 11.32\n\ndef objective(trial):\n    # Thử các tham số\n    param = {\n        'n_estimators': 200,\n        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n        'max_depth': trial.suggest_int('max_depth', 3, 10),\n        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n        'gamma': trial.suggest_float('gamma', 0, 5),\n        # 'scale_pos_weight': SCALE_POS_WEIGHT,\n        'random_state': 42,\n        'verbosity': 0,\n        'n_jobs': -1,\n        'use_label_encoder': False,\n        'eval_metric': 'logloss'\n    }\n\n    model = xgb.XGBClassifier(**param)\n    model.fit(X_train_scaled, y_smenn)\n\n    # Dự đoán xác suất\n    y_probs = model.predict_proba(X_test_scaled)[:, 1]\n    y_pred = (y_probs >= THRESHOLD).astype(int)\n\n    # Trả về F1-score của lớp mưa (label=1)\n    return f1_score(y_test, y_pred, pos_label=1)\n\n\n# Tối ưu với Optuna\nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=30)  # Có thể tăng trials lên 100+\n\n# In kết quả tốt nhất\nprint(\"Best trial:\")\nprint(study.best_trial)\nprint(\"Best hyperparameters:\")\nfor key, value in study.best_trial.params.items():\n    print(f\"{key}: {value}\")\n\n# Huấn luyện lại với tham số tốt nhất\nbest_params = study.best_trial.params\nbest_params.update({\n    'n_estimators': 200,\n    # 'scale_pos_weight': SCALE_POS_WEIGHT,\n    'random_state': 42,\n    'use_label_encoder': False,\n    'eval_metric': 'logloss'\n})\n\nbest_model = xgb.XGBClassifier(**best_params)\nbest_model.fit(X_train_scaled, y_smenn)\n\n# Dự đoán với threshold \ny_probs = best_model.predict_proba(X_test_scaled)[:, 1]\ny_pred_thresh = (y_probs >= THRESHOLD).astype(int)\n\n# In kết quả\nfrom sklearn.metrics import classification_report\nprint(f\"\\nClassification report with threshold = {THRESHOLD}:\")\nprint(classification_report(y_test, y_pred_thresh))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T04:53:52.762373Z","iopub.execute_input":"2025-05-04T04:53:52.762717Z","iopub.status.idle":"2025-05-04T04:59:24.962653Z","shell.execute_reply.started":"2025-05-04T04:53:52.762684Z","shell.execute_reply":"2025-05-04T04:59:24.961767Z"}},"outputs":[{"name":"stderr","text":"[I 2025-05-04 04:53:52,771] A new study created in memory with name: no-name-1fb200fe-0772-4d23-983b-24ac96e5e6c6\n[I 2025-05-04 04:54:01,222] Trial 0 finished with value: 0.6451217670062603 and parameters: {'learning_rate': 0.10173756277259545, 'max_depth': 4, 'min_child_weight': 5, 'subsample': 0.7505247483175883, 'colsample_bytree': 0.5442605960408098, 'gamma': 3.2374930930885117}. Best is trial 0 with value: 0.6451217670062603.\n[I 2025-05-04 04:54:13,928] Trial 1 finished with value: 0.5697583966321954 and parameters: {'learning_rate': 0.2667013479035525, 'max_depth': 8, 'min_child_weight': 4, 'subsample': 0.8689759940338972, 'colsample_bytree': 0.9112882239957628, 'gamma': 1.9757545464427357}. Best is trial 0 with value: 0.6451217670062603.\n[I 2025-05-04 04:54:26,688] Trial 2 finished with value: 0.6068104331820368 and parameters: {'learning_rate': 0.26630603080984805, 'max_depth': 9, 'min_child_weight': 7, 'subsample': 0.7482758440863413, 'colsample_bytree': 0.7278139326859422, 'gamma': 3.187160025778784}. Best is trial 0 with value: 0.6451217670062603.\n[I 2025-05-04 04:54:38,097] Trial 3 finished with value: 0.5518437692350737 and parameters: {'learning_rate': 0.1938191117535043, 'max_depth': 7, 'min_child_weight': 4, 'subsample': 0.6955552898087656, 'colsample_bytree': 0.8301653835060198, 'gamma': 0.7183724254499146}. Best is trial 0 with value: 0.6451217670062603.\n[I 2025-05-04 04:54:51,997] Trial 4 finished with value: 0.6549344310274833 and parameters: {'learning_rate': 0.06858118850837037, 'max_depth': 7, 'min_child_weight': 7, 'subsample': 0.6842106391650988, 'colsample_bytree': 0.9232644972567426, 'gamma': 1.8976836398942059}. Best is trial 4 with value: 0.6549344310274833.\n[I 2025-05-04 04:55:02,155] Trial 5 finished with value: 0.636418837535711 and parameters: {'learning_rate': 0.21036763796212377, 'max_depth': 6, 'min_child_weight': 3, 'subsample': 0.5126461621601885, 'colsample_bytree': 0.6419942242583343, 'gamma': 4.426060173103199}. Best is trial 4 with value: 0.6549344310274833.\n[I 2025-05-04 04:55:12,921] Trial 6 finished with value: 0.5821066280222713 and parameters: {'learning_rate': 0.25736576642350817, 'max_depth': 9, 'min_child_weight': 3, 'subsample': 0.6801418967774432, 'colsample_bytree': 0.7178985095956334, 'gamma': 4.457799599053793}. Best is trial 4 with value: 0.6549344310274833.\n[I 2025-05-04 04:55:21,658] Trial 7 finished with value: 0.6530619089140787 and parameters: {'learning_rate': 0.2175681972633547, 'max_depth': 3, 'min_child_weight': 3, 'subsample': 0.5750662240244986, 'colsample_bytree': 0.5493858196197308, 'gamma': 1.565505222328728}. Best is trial 4 with value: 0.6549344310274833.\n[I 2025-05-04 04:55:38,252] Trial 8 finished with value: 0.5565899179790766 and parameters: {'learning_rate': 0.18503203322294645, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.8133729576620443, 'colsample_bytree': 0.9795517907623967, 'gamma': 0.05983275363717622}. Best is trial 4 with value: 0.6549344310274833.\n[I 2025-05-04 04:55:57,499] Trial 9 finished with value: 0.625805785123967 and parameters: {'learning_rate': 0.05889826344282487, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.8263933694821333, 'colsample_bytree': 0.9480643794025482, 'gamma': 4.936486683271152}. Best is trial 4 with value: 0.6549344310274833.\n[I 2025-05-04 04:56:07,040] Trial 10 finished with value: 0.6396764421632246 and parameters: {'learning_rate': 0.031065537611068797, 'max_depth': 5, 'min_child_weight': 10, 'subsample': 0.9499426630196508, 'colsample_bytree': 0.8504969772589867, 'gamma': 2.803046593417356}. Best is trial 4 with value: 0.6549344310274833.\n[I 2025-05-04 04:56:14,328] Trial 11 finished with value: 0.6496768605503364 and parameters: {'learning_rate': 0.12152067604332517, 'max_depth': 3, 'min_child_weight': 7, 'subsample': 0.5682226835499135, 'colsample_bytree': 0.5141929221711328, 'gamma': 1.602751262873041}. Best is trial 4 with value: 0.6549344310274833.\n[I 2025-05-04 04:56:26,028] Trial 12 finished with value: 0.6535605575912676 and parameters: {'learning_rate': 0.12782211926201464, 'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.6135757769169256, 'colsample_bytree': 0.6029019867695496, 'gamma': 1.3289481872467224}. Best is trial 4 with value: 0.6549344310274833.\n[I 2025-05-04 04:56:36,706] Trial 13 finished with value: 0.6594648937280082 and parameters: {'learning_rate': 0.09799491003362454, 'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.6272925372325973, 'colsample_bytree': 0.6353625859869455, 'gamma': 0.8314606418155579}. Best is trial 13 with value: 0.6594648937280082.\n[I 2025-05-04 04:56:48,950] Trial 14 finished with value: 0.660188789142313 and parameters: {'learning_rate': 0.07743599666157772, 'max_depth': 7, 'min_child_weight': 8, 'subsample': 0.6474353212038578, 'colsample_bytree': 0.7978694791442308, 'gamma': 0.7198542118633011}. Best is trial 14 with value: 0.660188789142313.\n[I 2025-05-04 04:57:00,753] Trial 15 finished with value: 0.630163908018203 and parameters: {'learning_rate': 0.01996342685982816, 'max_depth': 5, 'min_child_weight': 10, 'subsample': 0.6229741431585861, 'colsample_bytree': 0.7871434008775284, 'gamma': 0.07996154294075353}. Best is trial 14 with value: 0.660188789142313.\n[I 2025-05-04 04:57:14,619] Trial 16 finished with value: 0.6286855954109638 and parameters: {'learning_rate': 0.08557677628978493, 'max_depth': 8, 'min_child_weight': 1, 'subsample': 0.6274233738735054, 'colsample_bytree': 0.6928345524192236, 'gamma': 0.8260098984897712}. Best is trial 14 with value: 0.660188789142313.\n[I 2025-05-04 04:57:23,850] Trial 17 finished with value: 0.6626926247701186 and parameters: {'learning_rate': 0.1419487965980065, 'max_depth': 5, 'min_child_weight': 8, 'subsample': 0.5124467132278269, 'colsample_bytree': 0.6391332404096435, 'gamma': 0.7824951016551797}. Best is trial 17 with value: 0.6626926247701186.\n[I 2025-05-04 04:57:34,443] Trial 18 finished with value: 0.6593043320316048 and parameters: {'learning_rate': 0.15054050969604946, 'max_depth': 5, 'min_child_weight': 9, 'subsample': 0.528929891760554, 'colsample_bytree': 0.7845561135998731, 'gamma': 0.5036488100130787}. Best is trial 17 with value: 0.6626926247701186.\n[I 2025-05-04 04:57:42,999] Trial 19 finished with value: 0.6598053514589467 and parameters: {'learning_rate': 0.161437982019311, 'max_depth': 4, 'min_child_weight': 8, 'subsample': 0.5592208180197055, 'colsample_bytree': 0.8552422699603922, 'gamma': 1.188219087986061}. Best is trial 17 with value: 0.6626926247701186.\n[I 2025-05-04 04:57:56,612] Trial 20 finished with value: 0.6540728681300173 and parameters: {'learning_rate': 0.048173207194714726, 'max_depth': 8, 'min_child_weight': 8, 'subsample': 0.5001588100736357, 'colsample_bytree': 0.6662154621066243, 'gamma': 2.4808412847417407}. Best is trial 17 with value: 0.6626926247701186.\n[I 2025-05-04 04:58:06,293] Trial 21 finished with value: 0.6622571162257116 and parameters: {'learning_rate': 0.16831016518022412, 'max_depth': 4, 'min_child_weight': 8, 'subsample': 0.5677976652439811, 'colsample_bytree': 0.8685555105831221, 'gamma': 1.2670524947717499}. Best is trial 17 with value: 0.6626926247701186.\n[I 2025-05-04 04:58:14,572] Trial 22 finished with value: 0.6635276106383736 and parameters: {'learning_rate': 0.15831976529718217, 'max_depth': 4, 'min_child_weight': 8, 'subsample': 0.5781021981205159, 'colsample_bytree': 0.776009200044843, 'gamma': 0.3723572466435703}. Best is trial 22 with value: 0.6635276106383736.\n[I 2025-05-04 04:58:22,786] Trial 23 finished with value: 0.657862429408257 and parameters: {'learning_rate': 0.15899796756516849, 'max_depth': 4, 'min_child_weight': 9, 'subsample': 0.5687357953606204, 'colsample_bytree': 0.885531497518109, 'gamma': 0.3708170670495212}. Best is trial 22 with value: 0.6635276106383736.\n[I 2025-05-04 04:58:31,283] Trial 24 finished with value: 0.6614150851235779 and parameters: {'learning_rate': 0.13552494368171733, 'max_depth': 4, 'min_child_weight': 6, 'subsample': 0.5360023739696569, 'colsample_bytree': 0.7554450496529048, 'gamma': 1.0923679010531395}. Best is trial 22 with value: 0.6635276106383736.\n[I 2025-05-04 04:58:39,561] Trial 25 finished with value: 0.6566799298624224 and parameters: {'learning_rate': 0.23387149986466427, 'max_depth': 3, 'min_child_weight': 9, 'subsample': 0.594412751547271, 'colsample_bytree': 0.599054967418249, 'gamma': 2.13392504266021}. Best is trial 22 with value: 0.6635276106383736.\n[I 2025-05-04 04:58:48,702] Trial 26 finished with value: 0.6584598296927064 and parameters: {'learning_rate': 0.1827848873495771, 'max_depth': 5, 'min_child_weight': 6, 'subsample': 0.5404573062799347, 'colsample_bytree': 0.8197696024688186, 'gamma': 0.25314592948477854}. Best is trial 22 with value: 0.6635276106383736.\n[I 2025-05-04 04:58:56,656] Trial 27 finished with value: 0.6438456944528592 and parameters: {'learning_rate': 0.11343664095017822, 'max_depth': 4, 'min_child_weight': 8, 'subsample': 0.7345899256201733, 'colsample_bytree': 0.7498777084952893, 'gamma': 1.4348573046772937}. Best is trial 22 with value: 0.6635276106383736.\n[I 2025-05-04 04:59:07,526] Trial 28 finished with value: 0.6623675284107243 and parameters: {'learning_rate': 0.17540537353113367, 'max_depth': 5, 'min_child_weight': 7, 'subsample': 0.502613360586811, 'colsample_bytree': 0.6905565500346931, 'gamma': 0.9705892696576881}. Best is trial 22 with value: 0.6635276106383736.\n[I 2025-05-04 04:59:16,667] Trial 29 finished with value: 0.6613297672586717 and parameters: {'learning_rate': 0.14417521285755477, 'max_depth': 5, 'min_child_weight': 7, 'subsample': 0.501548328782908, 'colsample_bytree': 0.6935079331188742, 'gamma': 2.296693023567244}. Best is trial 22 with value: 0.6635276106383736.\n","output_type":"stream"},{"name":"stdout","text":"Best trial:\nFrozenTrial(number=22, state=1, values=[0.6635276106383736], datetime_start=datetime.datetime(2025, 5, 4, 4, 58, 6, 294344), datetime_complete=datetime.datetime(2025, 5, 4, 4, 58, 14, 571990), params={'learning_rate': 0.15831976529718217, 'max_depth': 4, 'min_child_weight': 8, 'subsample': 0.5781021981205159, 'colsample_bytree': 0.776009200044843, 'gamma': 0.3723572466435703}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'learning_rate': FloatDistribution(high=0.3, log=False, low=0.01, step=None), 'max_depth': IntDistribution(high=10, log=False, low=3, step=1), 'min_child_weight': IntDistribution(high=10, log=False, low=1, step=1), 'subsample': FloatDistribution(high=1.0, log=False, low=0.5, step=None), 'colsample_bytree': FloatDistribution(high=1.0, log=False, low=0.5, step=None), 'gamma': FloatDistribution(high=5.0, log=False, low=0.0, step=None)}, trial_id=22, value=None)\nBest hyperparameters:\nlearning_rate: 0.15831976529718217\nmax_depth: 4\nmin_child_weight: 8\nsubsample: 0.5781021981205159\ncolsample_bytree: 0.776009200044843\ngamma: 0.3723572466435703\n\nClassification report with threshold = 0.7000000000000002:\n              precision    recall  f1-score   support\n\n           0       0.93      0.83      0.87    159566\n           1       0.58      0.78      0.66     47528\n\n    accuracy                           0.82    207094\n   macro avg       0.75      0.81      0.77    207094\nweighted avg       0.85      0.82      0.83    207094\n\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"import xgboost as xgb\n\nmodel_xgb = xgb.XGBClassifier(\n    n_estimators=200,\n    max_depth=6,\n    learning_rate=0.1,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    # scale_pos_weight=11.32,\n    random_state=42\n)\nmodel_xgb.fit(X_train_scaled[top_features], y_smenn)\n\n\ny_pred = model_xgb.predict(X_test_scaled[top_features])\nprint_scores(y_test, y_pred)\n\ny_probs = model_xgb.predict_proba(X_test_scaled[top_features])[:,1]\n\nbest_thresh = 0.0\nbest_f1 = 0.0\nfor t in np.arange(0.1, 0.9, 0.05):\n    y_pred = (y_probs >= t).astype(int)\n    f1 = f1_score(y_test, y_pred)\n    if f1 > best_f1:\n        best_f1 = f1\n        best_thresh = t\n\nprint(f\"Best threshold: {best_thresh}, F1: {best_f1}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T04:59:24.963923Z","iopub.execute_input":"2025-05-04T04:59:24.964239Z","iopub.status.idle":"2025-05-04T04:59:33.899896Z","shell.execute_reply.started":"2025-05-04T04:59:24.964207Z","shell.execute_reply":"2025-05-04T04:59:33.898685Z"}},"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.95      0.72      0.82    159566\n           1       0.48      0.87      0.62     47528\n\n    accuracy                           0.75    207094\n   macro avg       0.71      0.79      0.72    207094\nweighted avg       0.84      0.75      0.77    207094\n\nBest threshold: 0.7500000000000002, F1: 0.6505599104143338\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"import optuna\nimport numpy as np\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import train_test_split\nimport xgboost as xgb\n\nTHRESHOLD = best_thresh\n# SCALE_POS_WEIGHT = 11.32\n\ndef objective(trial):\n    # Thử các tham số\n    param = {\n        'n_estimators': 200,\n        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n        'max_depth': trial.suggest_int('max_depth', 3, 10),\n        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n        'gamma': trial.suggest_float('gamma', 0, 5),\n        # 'scale_pos_weight': SCALE_POS_WEIGHT,\n        'random_state': 42,\n        'verbosity': 0,\n        'n_jobs': -1,\n        'use_label_encoder': False,\n        'eval_metric': 'logloss'\n    }\n\n    model = xgb.XGBClassifier(**param)\n    model.fit(X_train_scaled[top_features], y_smenn)\n\n    # Dự đoán xác suất\n    y_probs = model.predict_proba(X_test_scaled[top_features])[:, 1]\n    y_pred = (y_probs >= THRESHOLD).astype(int)\n\n    # Trả về F1-score của lớp mưa (label=1)\n    return f1_score(y_test, y_pred, pos_label=1)\n\n\n# Tối ưu với Optuna\nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=30)  # Có thể tăng trials lên 100+\n\n# In kết quả tốt nhất\nprint(\"Best trial:\")\nprint(study.best_trial)\nprint(\"Best hyperparameters:\")\nfor key, value in study.best_trial.params.items():\n    print(f\"{key}: {value}\")\n\n# Huấn luyện lại với tham số tốt nhất\nbest_params = study.best_trial.params\nbest_params.update({\n    'n_estimators': 200,\n    # 'scale_pos_weight': SCALE_POS_WEIGHT,\n    'random_state': 42,\n    'use_label_encoder': False,\n    'eval_metric': 'logloss'\n})\n\nbest_model = xgb.XGBClassifier(**best_params)\nbest_model.fit(X_train_scaled[top_features], y_smenn)\n\n# Dự đoán với threshold\ny_probs = best_model.predict_proba(X_test_scaled[top_features])[:, 1]\ny_pred_thresh = (y_probs >= THRESHOLD).astype(int)\n\n# In kết quả\nfrom sklearn.metrics import classification_report\nprint(f\"\\nClassification report with threshold = {THRESHOLD}:\")\nprint(classification_report(y_test, y_pred_thresh))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T04:59:33.901284Z","iopub.execute_input":"2025-05-04T04:59:33.901653Z","iopub.status.idle":"2025-05-04T05:03:09.115667Z","shell.execute_reply.started":"2025-05-04T04:59:33.901622Z","shell.execute_reply":"2025-05-04T05:03:09.114712Z"}},"outputs":[{"name":"stderr","text":"[I 2025-05-04 04:59:33,910] A new study created in memory with name: no-name-e3d8a4fb-d246-4867-aabf-f9274090d51f\n[I 2025-05-04 04:59:44,506] Trial 0 finished with value: 0.49340167451353295 and parameters: {'learning_rate': 0.23999753530562806, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.5069463319353236, 'colsample_bytree': 0.56205689541778, 'gamma': 1.5645382833343264}. Best is trial 0 with value: 0.49340167451353295.\n[I 2025-05-04 04:59:53,814] Trial 1 finished with value: 0.5831251734665557 and parameters: {'learning_rate': 0.07911671646508799, 'max_depth': 8, 'min_child_weight': 6, 'subsample': 0.6529614109903809, 'colsample_bytree': 0.6919299226229674, 'gamma': 2.073126153197962}. Best is trial 1 with value: 0.5831251734665557.\n[I 2025-05-04 05:00:00,943] Trial 2 finished with value: 0.6098351962144082 and parameters: {'learning_rate': 0.13377602262172292, 'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.7242269093063951, 'colsample_bytree': 0.5578146540992005, 'gamma': 0.5982257804054808}. Best is trial 2 with value: 0.6098351962144082.\n[I 2025-05-04 05:00:07,770] Trial 3 finished with value: 0.567021019823488 and parameters: {'learning_rate': 0.27904254146423957, 'max_depth': 6, 'min_child_weight': 7, 'subsample': 0.7984953318979406, 'colsample_bytree': 0.519724544348309, 'gamma': 4.456960429450082}. Best is trial 2 with value: 0.6098351962144082.\n[I 2025-05-04 05:00:16,954] Trial 4 finished with value: 0.5261120503701977 and parameters: {'learning_rate': 0.2240500955391331, 'max_depth': 7, 'min_child_weight': 9, 'subsample': 0.6172771936440757, 'colsample_bytree': 0.8908286354084272, 'gamma': 3.377060787581957}. Best is trial 2 with value: 0.6098351962144082.\n[I 2025-05-04 05:00:24,099] Trial 5 finished with value: 0.5757595401702753 and parameters: {'learning_rate': 0.19244933914354506, 'max_depth': 6, 'min_child_weight': 3, 'subsample': 0.7223328742003878, 'colsample_bytree': 0.8320708005620447, 'gamma': 2.0185823113375925}. Best is trial 2 with value: 0.6098351962144082.\n[I 2025-05-04 05:00:30,539] Trial 6 finished with value: 0.6420278570810624 and parameters: {'learning_rate': 0.059302798280420316, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.7921866448427359, 'colsample_bytree': 0.9658175964333442, 'gamma': 4.955089745539027}. Best is trial 6 with value: 0.6420278570810624.\n[I 2025-05-04 05:00:37,354] Trial 7 finished with value: 0.5405283206546926 and parameters: {'learning_rate': 0.24180013702890718, 'max_depth': 6, 'min_child_weight': 5, 'subsample': 0.869314607066679, 'colsample_bytree': 0.6930897783085153, 'gamma': 1.9921190708410486}. Best is trial 6 with value: 0.6420278570810624.\n[I 2025-05-04 05:00:50,369] Trial 8 finished with value: 0.6122408213814869 and parameters: {'learning_rate': 0.043521074760615786, 'max_depth': 9, 'min_child_weight': 2, 'subsample': 0.6611595139690186, 'colsample_bytree': 0.7440938510427137, 'gamma': 0.6930135522591235}. Best is trial 6 with value: 0.6420278570810624.\n[I 2025-05-04 05:00:56,695] Trial 9 finished with value: 0.6337174280551076 and parameters: {'learning_rate': 0.18391959628496854, 'max_depth': 5, 'min_child_weight': 5, 'subsample': 0.5531052041522708, 'colsample_bytree': 0.5949522252059888, 'gamma': 1.6111770848662181}. Best is trial 6 with value: 0.6420278570810624.\n[I 2025-05-04 05:01:01,930] Trial 10 finished with value: 0.618363692978359 and parameters: {'learning_rate': 0.013612005537184613, 'max_depth': 3, 'min_child_weight': 10, 'subsample': 0.9955324858880208, 'colsample_bytree': 0.9899893021729227, 'gamma': 4.752061040004878}. Best is trial 6 with value: 0.6420278570810624.\n[I 2025-05-04 05:01:07,651] Trial 11 finished with value: 0.6484357754015417 and parameters: {'learning_rate': 0.13127022834560206, 'max_depth': 4, 'min_child_weight': 4, 'subsample': 0.5047041878010263, 'colsample_bytree': 0.9874703449990975, 'gamma': 3.303059054028588}. Best is trial 11 with value: 0.6484357754015417.\n[I 2025-05-04 05:01:12,866] Trial 12 finished with value: 0.6469891701743318 and parameters: {'learning_rate': 0.11323616424311905, 'max_depth': 3, 'min_child_weight': 1, 'subsample': 0.8651855729269542, 'colsample_bytree': 0.9958869871740184, 'gamma': 3.4960304036914924}. Best is trial 11 with value: 0.6484357754015417.\n[I 2025-05-04 05:01:18,261] Trial 13 finished with value: 0.6352088668853694 and parameters: {'learning_rate': 0.11952177738960348, 'max_depth': 3, 'min_child_weight': 4, 'subsample': 0.9117288641041921, 'colsample_bytree': 0.8953516977266944, 'gamma': 3.3246678127167786}. Best is trial 11 with value: 0.6484357754015417.\n[I 2025-05-04 05:01:23,685] Trial 14 finished with value: 0.6408079443115848 and parameters: {'learning_rate': 0.10877128532939893, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.8995191086819421, 'colsample_bytree': 0.9175189036937396, 'gamma': 3.384143964748028}. Best is trial 11 with value: 0.6484357754015417.\n[I 2025-05-04 05:01:29,222] Trial 15 finished with value: 0.6416930675894055 and parameters: {'learning_rate': 0.1481581118021312, 'max_depth': 4, 'min_child_weight': 3, 'subsample': 0.9706178790820728, 'colsample_bytree': 0.8124685713895416, 'gamma': 4.00188239064348}. Best is trial 11 with value: 0.6484357754015417.\n[I 2025-05-04 05:01:34,737] Trial 16 finished with value: 0.6448073916384739 and parameters: {'learning_rate': 0.10109231720055242, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.8198236619578362, 'colsample_bytree': 0.9959609999481962, 'gamma': 2.8178170738457737}. Best is trial 11 with value: 0.6484357754015417.\n[I 2025-05-04 05:01:39,845] Trial 17 finished with value: 0.63669228114157 and parameters: {'learning_rate': 0.18116677284949426, 'max_depth': 3, 'min_child_weight': 4, 'subsample': 0.5822141092266835, 'colsample_bytree': 0.8272588314729132, 'gamma': 4.076080785199243}. Best is trial 11 with value: 0.6484357754015417.\n[I 2025-05-04 05:01:52,651] Trial 18 finished with value: 0.4668503530222146 and parameters: {'learning_rate': 0.1554086366134624, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.5014929222663338, 'colsample_bytree': 0.9288743786470955, 'gamma': 2.8045243459747375}. Best is trial 11 with value: 0.6484357754015417.\n[I 2025-05-04 05:01:59,052] Trial 19 finished with value: 0.6492858923674182 and parameters: {'learning_rate': 0.08663175933599757, 'max_depth': 5, 'min_child_weight': 7, 'subsample': 0.6817556451733409, 'colsample_bytree': 0.8567862350060883, 'gamma': 3.8828372418848125}. Best is trial 19 with value: 0.6492858923674182.\n[I 2025-05-04 05:02:05,319] Trial 20 finished with value: 0.6465649757597256 and parameters: {'learning_rate': 0.07989569948867846, 'max_depth': 5, 'min_child_weight': 8, 'subsample': 0.6769975563228724, 'colsample_bytree': 0.7822043577962559, 'gamma': 4.043493733982502}. Best is trial 19 with value: 0.6492858923674182.\n[I 2025-05-04 05:02:10,984] Trial 21 finished with value: 0.6480006924009001 and parameters: {'learning_rate': 0.08146261138712141, 'max_depth': 4, 'min_child_weight': 6, 'subsample': 0.7600927789871815, 'colsample_bytree': 0.9431564205794217, 'gamma': 3.644075106435089}. Best is trial 19 with value: 0.6492858923674182.\n[I 2025-05-04 05:02:17,078] Trial 22 finished with value: 0.6335001622738841 and parameters: {'learning_rate': 0.02601722764945355, 'max_depth': 4, 'min_child_weight': 6, 'subsample': 0.7495381132166125, 'colsample_bytree': 0.8702967495708872, 'gamma': 2.8802839134548237}. Best is trial 19 with value: 0.6492858923674182.\n[I 2025-05-04 05:02:24,094] Trial 23 finished with value: 0.6457343669980752 and parameters: {'learning_rate': 0.07791394738821499, 'max_depth': 5, 'min_child_weight': 7, 'subsample': 0.5693602077584378, 'colsample_bytree': 0.9430514641120032, 'gamma': 3.9027475604641952}. Best is trial 19 with value: 0.6492858923674182.\n[I 2025-05-04 05:02:29,822] Trial 24 finished with value: 0.6449018669219723 and parameters: {'learning_rate': 0.057138241231430145, 'max_depth': 4, 'min_child_weight': 8, 'subsample': 0.6966861306382712, 'colsample_bytree': 0.8750377373693556, 'gamma': 4.418276103573047}. Best is trial 19 with value: 0.6492858923674182.\n[I 2025-05-04 05:02:36,118] Trial 25 finished with value: 0.6427549687702683 and parameters: {'learning_rate': 0.09201331506439502, 'max_depth': 5, 'min_child_weight': 5, 'subsample': 0.6167955413663402, 'colsample_bytree': 0.9469325013357724, 'gamma': 3.698784578667998}. Best is trial 19 with value: 0.6492858923674182.\n[I 2025-05-04 05:02:44,027] Trial 26 finished with value: 0.496804542538785 and parameters: {'learning_rate': 0.15709315031137044, 'max_depth': 7, 'min_child_weight': 6, 'subsample': 0.7605025740380064, 'colsample_bytree': 0.8556433027452179, 'gamma': 3.1138555305621853}. Best is trial 19 with value: 0.6492858923674182.\n[I 2025-05-04 05:02:51,413] Trial 27 finished with value: 0.6438038550714607 and parameters: {'learning_rate': 0.0431549797004012, 'max_depth': 4, 'min_child_weight': 8, 'subsample': 0.6158709588778021, 'colsample_bytree': 0.9057872900337429, 'gamma': 2.4829140950566693}. Best is trial 19 with value: 0.6492858923674182.\n[I 2025-05-04 05:02:57,684] Trial 28 finished with value: 0.613993915688831 and parameters: {'learning_rate': 0.13930576060641722, 'max_depth': 5, 'min_child_weight': 4, 'subsample': 0.5377521341586529, 'colsample_bytree': 0.774243448589923, 'gamma': 4.413941773187989}. Best is trial 19 with value: 0.6492858923674182.\n[I 2025-05-04 05:03:02,537] Trial 29 finished with value: 0.6402725299808917 and parameters: {'learning_rate': 0.1311507384303732, 'max_depth': 3, 'min_child_weight': 9, 'subsample': 0.8207878091868869, 'colsample_bytree': 0.9638231853461265, 'gamma': 2.46245153738694}. Best is trial 19 with value: 0.6492858923674182.\n","output_type":"stream"},{"name":"stdout","text":"Best trial:\nFrozenTrial(number=19, state=1, values=[0.6492858923674182], datetime_start=datetime.datetime(2025, 5, 4, 5, 1, 52, 651932), datetime_complete=datetime.datetime(2025, 5, 4, 5, 1, 59, 52578), params={'learning_rate': 0.08663175933599757, 'max_depth': 5, 'min_child_weight': 7, 'subsample': 0.6817556451733409, 'colsample_bytree': 0.8567862350060883, 'gamma': 3.8828372418848125}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'learning_rate': FloatDistribution(high=0.3, log=False, low=0.01, step=None), 'max_depth': IntDistribution(high=10, log=False, low=3, step=1), 'min_child_weight': IntDistribution(high=10, log=False, low=1, step=1), 'subsample': FloatDistribution(high=1.0, log=False, low=0.5, step=None), 'colsample_bytree': FloatDistribution(high=1.0, log=False, low=0.5, step=None), 'gamma': FloatDistribution(high=5.0, log=False, low=0.0, step=None)}, trial_id=19, value=None)\nBest hyperparameters:\nlearning_rate: 0.08663175933599757\nmax_depth: 5\nmin_child_weight: 7\nsubsample: 0.6817556451733409\ncolsample_bytree: 0.8567862350060883\ngamma: 3.8828372418848125\n\nClassification report with threshold = 0.7500000000000002:\n              precision    recall  f1-score   support\n\n           0       0.92      0.82      0.87    159566\n           1       0.56      0.77      0.65     47528\n\n    accuracy                           0.81    207094\n   macro avg       0.74      0.79      0.76    207094\nweighted avg       0.84      0.81      0.82    207094\n\n","output_type":"stream"}],"execution_count":37},{"cell_type":"markdown","source":"# 7. Kết luận","metadata":{}},{"cell_type":"markdown","source":"Mô hình XGBoost ban đầu (không SMOTE hay SMOTE ENN) là tốt nhất.","metadata":{}}]}